// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.3.2 (swiftlang-1200.0.45 clang-1200.0.32.28)
// swift-module-flags: -target arm64-apple-ios13.1-macabi -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -module-name AudioKit
import AVFoundation
import Accelerate
import AudioToolbox
import CAudioKit
import CoreAudio
import CoreAudioKit
import CoreMIDI
import Darwin
import Foundation
import Swift
import os.log
import os
import soundpipe
extension AVAudioFile {
  public var duration: Foundation.TimeInterval {
    get
  }
  public var peak: AVFoundation.AVAudioPCMBuffer.Peak? {
    get
  }
  convenience public init(url: Foundation.URL, fromBuffer buffer: AVFoundation.AVAudioPCMBuffer) throws
  public func toAVAudioPCMBuffer() -> AVFoundation.AVAudioPCMBuffer?
  public func toFloatChannelData() -> AudioKit.FloatChannelData?
  @discardableResult
  public func extract(to outputURL: Foundation.URL, from startTime: Foundation.TimeInterval, to endTime: Foundation.TimeInterval, fadeInTime: Foundation.TimeInterval = 0, fadeOutTime: Foundation.TimeInterval = 0) -> AVFoundation.AVAudioFile?
  public func extract(to url: Foundation.URL, from startTime: Foundation.TimeInterval, to endTime: Foundation.TimeInterval, fadeInTime: Foundation.TimeInterval = 0, fadeOutTime: Foundation.TimeInterval = 0, options: AudioKit.FormatConverter.Options? = nil, completionHandler: AudioKit.FormatConverter.FormatConverterCallback? = nil)
}
extension AVURLAsset {
  public var audioFormat: AVFoundation.AVAudioFormat? {
    get
  }
}
extension AVAudioPCMBuffer {
  convenience public init?(url: Foundation.URL) throws
  convenience public init?(file: AVFoundation.AVAudioFile) throws
}
extension AVAudioPCMBuffer {
  public func toFloatChannelData() -> AudioKit.FloatChannelData?
}
extension AVAudioPCMBuffer {
  public struct Peak {
    public init()
    public var time: Swift.Double
    public var framePosition: Swift.Int
    public var amplitude: Swift.Float
  }
  public func peak() -> AVFoundation.AVAudioPCMBuffer.Peak?
  public func normalize() -> AVFoundation.AVAudioPCMBuffer?
  public func reverse() -> AVFoundation.AVAudioPCMBuffer?
  public func fade(inTime: Swift.Double, outTime: Swift.Double, linearRamp: Swift.Bool = false) -> AVFoundation.AVAudioPCMBuffer?
}
extension AVAudioPCMBuffer {
  public var md5: Swift.String {
    get
  }
  public func append(_ buffer: AVFoundation.AVAudioPCMBuffer)
  public func append(_ buffer: AVFoundation.AVAudioPCMBuffer, startingFrame: AVFoundation.AVAudioFramePosition, frameCount: AVFoundation.AVAudioFrameCount)
  @discardableResult
  public func copy(from buffer: AVFoundation.AVAudioPCMBuffer, readOffset: AVFoundation.AVAudioFrameCount = 0, frames: AVFoundation.AVAudioFrameCount = 0) -> AVFoundation.AVAudioFrameCount
  public func copyFrom(startSample: AVFoundation.AVAudioFrameCount) -> AVFoundation.AVAudioPCMBuffer?
  public func copyTo(count: AVFoundation.AVAudioFrameCount) -> AVFoundation.AVAudioPCMBuffer?
  public func extract(from startTime: Foundation.TimeInterval, to endTime: Foundation.TimeInterval) -> AVFoundation.AVAudioPCMBuffer?
}
extension FormatConverter {
  public class func isPCM(url: Foundation.URL, ignorePathExtension: Swift.Bool = false) -> Swift.Bool?
  public class func isCompressed(url: Foundation.URL, ignorePathExtension: Swift.Bool = false) -> Swift.Bool?
}
public class FormatConverter {
  public var inputURL: Foundation.URL?
  public var outputURL: Foundation.URL?
  public var options: AudioKit.FormatConverter.Options?
  public init(inputURL: Foundation.URL, outputURL: Foundation.URL, options: AudioKit.FormatConverter.Options? = nil)
  @objc deinit
  public func start(completionHandler: AudioKit.FormatConverter.FormatConverterCallback? = nil)
}
extension FormatConverter {
  public typealias FormatConverterCallback = (Swift.Error?) -> Swift.Void
  public static let outputFormats: [Swift.String]
  public static let inputFormats: [Swift.String]
  public enum BitDepthRule {
    case lessThanOrEqual
    case any
    public static func == (a: AudioKit.FormatConverter.BitDepthRule, b: AudioKit.FormatConverter.BitDepthRule) -> Swift.Bool
    public var hashValue: Swift.Int {
      get
    }
    public func hash(into hasher: inout Swift.Hasher)
  }
  public struct Options {
    public var format: Swift.String?
    public var sampleRate: Swift.Double?
    public var bitDepth: Swift.UInt32?
    public var bitRate: Swift.UInt32 {
      get
      set
    }
    public var bitDepthRule: AudioKit.FormatConverter.BitDepthRule
    public var channels: Swift.UInt32?
    public var isInterleaved: Swift.Bool?
    public var eraseFile: Swift.Bool
    public init()
    public init?(url: Foundation.URL)
    public init?(audioFile: AVFoundation.AVAudioFile)
    public init?(pcmFormat: Swift.String, sampleRate: Swift.Double? = nil, bitDepth: Swift.UInt32? = nil, channels: Swift.UInt32? = nil)
  }
}
public class WaveformDataRequest {
  public var audioFile: AVFoundation.AVAudioFile? {
    get
  }
  public var abortGetWaveformData: Swift.Bool {
    get
    set
  }
  public init(audioFile: AVFoundation.AVAudioFile)
  public init(url: Foundation.URL) throws
  @objc deinit
  public func getDataAsync(with samplesPerPixel: Swift.Int, queue: Dispatch.DispatchQueue = DispatchQueue.global(qos: .userInitiated), completionHandler: @escaping ((AudioKit.FloatChannelData?) -> Swift.Void))
  public func getData(with samplesPerPixel: Swift.Int) -> AudioKit.FloatChannelData?
  public func cancel()
}
extension AUParameterTree {
  public subscript(key: Swift.String) -> AudioToolbox.AUParameter? {
    get
  }
}
extension AudioComponentDescription {
  public init(type: Darwin.OSType, subType: Darwin.OSType)
  public init(appleEffect subType: Darwin.OSType)
  public init(effect subType: Darwin.OSType)
  public init(effect subType: Swift.String)
  public init(mixer subType: Swift.String)
  public init(generator subType: Swift.String)
  public init(instrument subType: Swift.String)
}
@objc @_inheritsConvenienceInitializers open class AudioKitAU : AudioToolbox.AUAudioUnit {
  @objc override dynamic public func allocateRenderResources() throws
  @objc override dynamic public func deallocateRenderResources()
  @objc override dynamic public func reset()
  @objc override dynamic public var inputBusses: AudioToolbox.AUAudioUnitBusArray {
    @objc get
  }
  @objc override dynamic public var outputBusses: AudioToolbox.AUAudioUnitBusArray {
    @objc get
  }
  @objc override dynamic public var internalRenderBlock: AudioToolbox.AUInternalRenderBlock {
    @objc get
  }
  @objc override dynamic public var parameterTree: AudioToolbox.AUParameterTree? {
    @objc get
    @objc set
  }
  @objc override dynamic public var canProcessInPlace: Swift.Bool {
    @objc get
  }
  @objc override dynamic public var shouldBypassEffect: Swift.Bool {
    @objc get
    @objc set
  }
  public var dsp: CAudioKit.DSPRef? {
    get
  }
  @objc override dynamic public init(componentDescription: AudioToolbox.AudioComponentDescription, options: AudioToolbox.AudioComponentInstantiationOptions = []) throws
  @objc deinit
  public func trigger(note: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity)
  public func trigger()
  public func setWavetable(_ wavetable: [AudioKit.AUValue], index: Swift.Int = 0)
  public func setWavetable(data: Swift.UnsafePointer<AudioKit.AUValue>?, size: Swift.Int, index: Swift.Int = 0)
}
extension OpaquePointer {
  public func getValue<T>(forProperty property: AudioToolbox.AudioUnitPropertyID) throws -> T
  public func setValue<T>(value: T, forProperty property: AudioToolbox.AudioUnitPropertyID) throws
  public func add(listener: AudioKit.AudioUnitPropertyListener, toProperty property: AudioToolbox.AudioUnitPropertyID) throws
  public func remove(listener: AudioKit.AudioUnitPropertyListener, fromProperty property: AudioToolbox.AudioUnitPropertyID)
}
public struct AudioUnitPropertyListener {
  public typealias AudioUnitPropertyListenerCallback = (AudioToolbox.AudioUnit, AudioToolbox.AudioUnitPropertyID) -> Swift.Void
  public init(callback: @escaping AudioKit.AudioUnitPropertyListener.AudioUnitPropertyListenerCallback)
}
extension OpaquePointer {
  public func getPropertyInfo(propertyID: AudioToolbox.AudioUnitPropertyID) throws -> (dataSize: Swift.UInt32, writable: Swift.Bool)
  public func getProperty<T>(propertyID: AudioToolbox.AudioUnitPropertyID, dataSize: Swift.UInt32) throws -> T
  public func setProperty<T>(propertyID: AudioToolbox.AudioUnitPropertyID, dataSize: Swift.UInt32, data: T) throws
}
extension Int32 {
  public func check() throws
}
extension AVAudioEngine {
  @available(iOS 11.0, OSX 10.13, tvOS 11.0, *)
  public func render(to audioFile: AVFoundation.AVAudioFile, maximumFrameCount: AVFoundation.AVAudioFrameCount = 4_096, duration: Swift.Double, renderUntilSilent: Swift.Bool = false, silenceThreshold: Swift.Float = 0.00005, prerender: (() -> Swift.Void)? = nil, progress progressHandler: ((Swift.Double) -> Swift.Void)? = nil) throws
}
extension AudioEngine {
  public var connectionTreeDescription: Swift.String {
    get
  }
}
extension AVAudioNode {
  public func disconnect(input: AVFoundation.AVAudioNode)
  public func connect(input: AVFoundation.AVAudioNode, bus: Swift.Int, format: AVFoundation.AVAudioFormat? = Settings.audioFormat)
}
extension AVAudioMixerNode {
  public func connectMixer(input: AVFoundation.AVAudioNode, format: AVFoundation.AVAudioFormat? = Settings.audioFormat)
}
public class AudioEngine {
  final public let avEngine: AVFoundation.AVAudioEngine
  public var mainMixerNode: AudioKit.Mixer? {
    get
  }
  @_inheritsConvenienceInitializers public class InputNode : AudioKit.Mixer {
    @objc deinit
    override public init(volume: AudioKit.AUValue = super, name: Swift.String? = super)
  }
  public var input: AudioKit.AudioEngine.InputNode? {
    get
  }
  public init()
  public var output: AudioKit.Node? {
    get
    set
  }
  public func rebuildGraph()
  public func start() throws
  public func stop()
  public func pause()
  public func startTest(totalDuration duration: Swift.Double) -> AVFoundation.AVAudioPCMBuffer
  public func render(duration: Swift.Double) -> AVFoundation.AVAudioPCMBuffer
  public static var inputDevices: [AudioKit.Device]? {
    get
  }
  public static var outputDevices: [AudioKit.Device]? {
    get
  }
  public static func setInputDevice(_ input: AudioKit.Device) throws
  public var inputDevice: AudioKit.Device? {
    get
  }
  public var outputDevice: AudioKit.Device? {
    get
  }
  @available(iOS 11, OSX 10.13, tvOS 11, *)
  public func renderToFile(_ audioFile: AVFoundation.AVAudioFile, maximumFrameCount: AVFoundation.AVAudioFrameCount = 4_096, duration: Swift.Double, prerender: (() -> Swift.Void)? = nil, progress: ((Swift.Double) -> Swift.Void)? = nil) throws
  @objc deinit
}
public func CheckError(_ error: Darwin.OSStatus)
public func ExceptionCatcher(_ operation: @escaping (() throws -> Swift.Void)) throws
public typealias DeviceID = Swift.String
public struct Device : Swift.Equatable, Swift.Hashable {
  public var name: Swift.String {
    get
  }
  public var nInputChannels: Swift.Int? {
    get
  }
  public var nOutputChannels: Swift.Int? {
    get
  }
  public var deviceID: AudioKit.DeviceID {
    get
  }
  public init(name: Swift.String, deviceID: AudioKit.DeviceID, dataSource: Swift.String = "")
  public init(portDescription: AVFoundation.AVAudioSessionPortDescription)
  public static func == (a: AudioKit.Device, b: AudioKit.Device) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
extension Device : Swift.CustomDebugStringConvertible {
  public var debugDescription: Swift.String {
    get
  }
}
extension TuningTable {
  public func momentOfSymmetry(generator gInput: Swift.Double = 7.0 / 12.0, level lInput: Swift.Int = 5, murchana mInput: Swift.Int = 0) -> Swift.Int
}
extension TuningTable {
  @discardableResult
  public func hexany(_ A: AudioKit.TuningTable.Frequency, _ B: AudioKit.TuningTable.Frequency, _ C: AudioKit.TuningTable.Frequency, _ D: AudioKit.TuningTable.Frequency) -> Swift.Int
  @discardableResult
  public func majorTetrany(_ A: AudioKit.TuningTable.Frequency, _ B: AudioKit.TuningTable.Frequency, _ C: AudioKit.TuningTable.Frequency, _ D: AudioKit.TuningTable.Frequency) -> Swift.Int
  @discardableResult
  public func minorTetrany(_ A: AudioKit.TuningTable.Frequency, _ B: AudioKit.TuningTable.Frequency, _ C: AudioKit.TuningTable.Frequency, _ D: AudioKit.TuningTable.Frequency) -> Swift.Int
}
extension TuningTable {
  public func defaultTuning() -> Swift.Int
  public func twelveToneEqualTemperament() -> Swift.Int
  public func thirtyOneEqualTemperament() -> Swift.Int
  public func equalTemperament(notesPerOctave npo: Swift.Int) -> Swift.Int
}
extension TuningTable {
  @discardableResult
  public func khiasmos22Indian() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian00_17() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian01Kalyan() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian02Bilawal() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian03Khamaj() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian04KafiOld() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian05Kafi() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian06Asawari() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian07Bhairavi() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian08Marwa() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian09Purvi() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian10Lalit2() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian11Todi() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian12Lalit() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian13NoName() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian14AnandBhairav() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian15Bhairav() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian16JogiyaTodi() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian17Madhubanti() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian18NatBhairav() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian19AhirBhairav() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian20ChandraKanada() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian21BasantMukhari() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian22Champakali() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian23Patdeep() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian24MohanKauns() -> Swift.Int
  @discardableResult
  public func presetPersian17NorthIndian25Parameswari() -> Swift.Int
}
extension TuningTable {
  @discardableResult
  public func presetRecurrenceRelation01() -> Swift.Int
}
extension TuningTable {
  public func scalaFile(_ filePath: Swift.String) -> Swift.Int?
  public func frequencies(fromScalaString rawStr: Swift.String?) -> [AudioKit.TuningTable.Frequency]?
}
extension TuningTable {
  public func presetHighlandBagPipes() -> Swift.Int
  public func presetDiaphonicTetrachord() -> Swift.Int
}
@objc public class TuningTableETNN : ObjectiveC.NSObject {
  public var nn: AudioKit.MIDINoteNumber
  public var pitchBend: Swift.Int
  public init(_ nn: AudioKit.MIDINoteNumber = 60, _ pb: Swift.Int = 16_384 / 2)
  @objc deinit
  @objc override dynamic public init()
}
@objc public class TuningTableDelta12ET : ObjectiveC.NSObject {
  public var nn: AudioKit.MIDINoteNumber
  public var cents: Swift.Double
  public init(_ nn: AudioKit.MIDINoteNumber = 60, _ cents: Swift.Double = 0)
  @objc deinit
  @objc override dynamic public init()
}
@objc @_inheritsConvenienceInitializers public class TuningTable : AudioKit.TuningTableBase {
  public var masterSet: [AudioKit.TuningTable.Frequency] {
    get
  }
  public var middleCNoteNumber: AudioKit.MIDINoteNumber {
    get
    set
  }
  public var middleCFrequency: Swift.Double {
    get
    set
  }
  public var middleCOctave: Swift.Int {
    get
    set
  }
  public var etNNPitchBendRangeDown: Swift.Double {
    get
    set
  }
  public var etNNPitchBendRangeUp: Swift.Double {
    get
    set
  }
  public func etNNPitchBend(NN nn: AudioKit.MIDINoteNumber) -> AudioKit.TuningTableETNN?
  public func delta12ET(NN nn: AudioKit.MIDINoteNumber) -> AudioKit.TuningTableDelta12ET?
  override public var npo: Swift.Int {
    get
  }
  @objc override dynamic public init()
  @discardableResult
  public func tuningTable(fromFrequencies inputMasterSet: [AudioKit.TuningTable.Frequency]) -> Swift.Int
  public func tuning12ETDeviation(centsArray: [AudioKit.TuningTable.Cents])
  public func masterSetInCents() -> [AudioKit.TuningTable.Cents]
  @objc deinit
}
@objc @_inheritsConvenienceInitializers open class TuningTableBase : ObjectiveC.NSObject {
  public typealias Frequency = Swift.Double
  public typealias Cents = Swift.Double
  public static let NYQUIST: Swift.Double
  public static let midiNoteCount: Swift.Int
  @objc override dynamic public init()
  public var npo: Swift.Int {
    get
  }
  public func frequency(forNoteNumber noteNumber: AudioKit.MIDINoteNumber) -> AudioKit.TuningTableBase.Frequency
  public func setFrequency(_ frequency: AudioKit.TuningTableBase.Frequency, at noteNumber: AudioKit.MIDINoteNumber)
  @objc deinit
}
extension Settings {
  public static var audioFormat: AVFoundation.AVAudioFormat {
    get
    set
  }
  public static var allowHapticsAndSystemSoundsDuringRecording: Swift.Bool {
    get
    set
  }
  public static var disableAVAudioSessionCategoryManagement: Swift.Bool
  public static var ioBufferDuration: Swift.Double {
    get
    set
  }
  public static let appSupportsBackgroundAudio: Swift.Bool
  public static let session: AVFoundation.AVAudioSession
  public static func setSession(category: AudioKit.Settings.SessionCategory, options: Swift.UInt) throws
  public static func setSession(category: AudioKit.Settings.SessionCategory, with options: AVFoundation.AVAudioSession.CategoryOptions = []) throws
  public static var headPhonesPlugged: Swift.Bool {
    get
  }
  public enum SessionCategory : Swift.Int, Swift.CustomStringConvertible {
    case ambient
    case soloAmbient
    case playback
    case record
    case playAndRecord
    case audioProcessing
    case multiRoute
    public var description: Swift.String {
      get
    }
    public var avCategory: AVFoundation.AVAudioSession.Category {
      get
    }
    public typealias RawValue = Swift.Int
    public init?(rawValue: Swift.Int)
    public var rawValue: Swift.Int {
      get
    }
  }
}
@objc @_inheritsConvenienceInitializers public class Settings : ObjectiveC.NSObject {
  public enum BufferLength : Swift.Int, Swift.CaseIterable {
    case shortest
    case veryShort
    case short
    case medium
    case long
    case veryLong
    case huge
    case longest
    public init?(bufferSizeInSamples: Swift.UInt)
    public var samplesCount: AVFoundation.AVAudioFrameCount {
      get
    }
    public var duration: Swift.Double {
      get
    }
    public typealias RawValue = Swift.Int
    public init?(rawValue: Swift.Int)
    public var rawValue: Swift.Int {
      get
    }
    public typealias AllCases = [AudioKit.Settings.BufferLength]
    public static var allCases: [AudioKit.Settings.BufferLength] {
      get
    }
  }
  public static let defaultAudioFormat: AVFoundation.AVAudioFormat
  public static var sampleRate: Swift.Double {
    get
    set
  }
  public static var channelCount: Swift.UInt32 {
    get
    set
  }
  public static var bufferLength: AudioKit.Settings.BufferLength
  public static var recordingBufferLength: AudioKit.Settings.BufferLength
  public static var fixTruncatedRecordings: Swift.Bool
  public static var enableLogging: Swift.Bool
  @objc deinit
  @objc override dynamic public init()
}
extension Table {
  public class func harmonicPitchRange(rootFrequency: Swift.Double = 8.175_798_915_643_75, octaveStepSize: Swift.Double = 1) -> [(Swift.Double, Swift.Int)]
  public class func harmonicFrequencyRange(f0: Swift.Double = 130.812_782_650_3, f1: Swift.Double = 2_093.004_522_404_8, wavetableCount: Swift.Int = 12) -> [(Swift.Double, Swift.Int)]
  public func sawtooth(harmonicCount: Swift.Int = 1_024, clear: Swift.Bool = true)
  public func square(harmonicCount: Swift.Int = 1_024, clear: Swift.Bool = true)
  public func triangle(harmonicCount: Swift.Int = 1_024, clear: Swift.Bool = true)
  public func pwm(harmonicCount: Swift.Int = 1_024, period: Swift.Float = 1 / 8)
  public func minMax() -> (min: Swift.Float, max: Swift.Float, absMax: Swift.Float)
  public func normalize()
  public func reverse()
  public func invert()
  public func msd(t: AudioKit.Table) -> AudioKit.Table.Element
  @available(OSX 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
  public class func createInterpolatedTables(inputTables: [AudioKit.Table], numberOfDesiredTables: Swift.Int = 256) -> [AudioKit.Table]
  public class func downSampleTables(inputTables: [AudioKit.Table], to sampleCount: Swift.Int = 64) -> [AudioKit.Table]
  public class func chopAudioToTables(signal: [Swift.Float], tableLength: Swift.Int = 2_048) -> [AudioKit.Table]
  @available(OSX 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
  public class func createWavetableArray(_ url: Foundation.URL, tableLength: Swift.Int = 2_048) -> [AudioKit.Table]?
}
public enum TableType {
  case sine
  case triangle
  case square
  case sawtooth
  case reverseSawtooth
  case positiveSine
  case positiveTriangle
  case positiveSquare
  case positiveSawtooth
  case positiveReverseSawtooth
  case harmonic([Swift.Float])
  case zero
  case custom
}
public class Table : Swift.MutableCollection {
  public typealias Index = Swift.Int
  public typealias IndexDistance = Swift.Int
  public typealias Element = Swift.Float
  public typealias SubSequence = Swift.ArraySlice<AudioKit.Table.Element>
  public var content: [AudioKit.Table.Element] {
    get
  }
  public var phase: Swift.Float {
    get
    set
  }
  public var startIndex: AudioKit.Table.Index {
    get
  }
  public var endIndex: AudioKit.Table.Index {
    get
  }
  public var count: AudioKit.Table.IndexDistance {
    get
  }
  public subscript(index: AudioKit.Table.Index) -> AudioKit.Table.Element {
    get
    set
  }
  public subscript(bounds: Swift.Range<AudioKit.Table.Index>) -> AudioKit.Table.SubSequence {
    get
    set
  }
  public init(_ type: AudioKit.TableType = .sine, phase: Swift.Float = 0, count: AudioKit.Table.IndexDistance = 4_096)
  public init(_ content: [AudioKit.Table.Element], phase: Swift.Float = 0)
  convenience public init?(file: AVFoundation.AVAudioFile)
  convenience public init?(url: Foundation.URL) throws
  public var phaseOffset: Swift.Int {
    @inline(__always) get
  }
  public typealias Iterator = Swift.IndexingIterator<AudioKit.Table>
  @objc deinit
}
extension Table : Swift.RandomAccessCollection {
  public typealias Indices = Swift.Array<AudioKit.Table.Element>.Indices
  @inline(__always) public func index(before i: AudioKit.Table.Index) -> AudioKit.Table.Index
  @inline(__always) public func index(after i: AudioKit.Table.Index) -> AudioKit.Table.Index
  @inline(__always) public func index(_ i: AudioKit.Table.Index, offsetBy n: AudioKit.Table.IndexDistance) -> AudioKit.Table.Index
  @inline(__always) public func formIndex(after i: inout AudioKit.Table.Index)
  @inline(__always) public func distance(from start: AudioKit.Table.Index, to end: AudioKit.Table.Index) -> AudioKit.Table.IndexDistance
}
extension AVAudioPCMBuffer {
  public func audition()
}
extension AVAudioTime {
  public func extrapolateTimeShimmed(fromAnchor anchorTime: AVFoundation.AVAudioTime) -> AVFoundation.AVAudioTime
  public static func now() -> AVFoundation.AVAudioTime
  public func offset(seconds: Swift.Double) -> AVFoundation.AVAudioTime
  public func timeIntervalSince(otherTime: AVFoundation.AVAudioTime) -> Swift.Double?
  public func toSeconds(hostTime time: Swift.UInt64) -> Swift.Double
  open class func secondsToAudioTime(hostTime: Swift.UInt64, time: Swift.Double) -> AVFoundation.AVAudioTime
}
public func + (left: AVFoundation.AVAudioTime, right: Swift.Double) -> AVFoundation.AVAudioTime
public func + (left: AVFoundation.AVAudioTime, right: Swift.Int) -> AVFoundation.AVAudioTime
public func - (left: AVFoundation.AVAudioTime, right: Swift.Double) -> AVFoundation.AVAudioTime
public func - (left: AVFoundation.AVAudioTime, right: Swift.Int) -> AVFoundation.AVAudioTime
infix operator ~== : ComparisonPrecedence
public func ~== (left: Swift.Double, right: Swift.Double) -> Swift.Bool
infix operator ~!= : ComparisonPrecedence
public func ~!= (left: Swift.Double, right: Swift.Double) -> Swift.Bool
infix operator ~<= : ComparisonPrecedence
public func ~<= (left: Swift.Double, right: Swift.Double) -> Swift.Bool
infix operator ~>= : ComparisonPrecedence
public func ~>= (left: Swift.Double, right: Swift.Double) -> Swift.Bool
infix operator ~< : ComparisonPrecedence
public func ~< (left: Swift.Double, right: Swift.Double) -> Swift.Bool
infix operator ~> : ComparisonPrecedence
public func ~> (left: Swift.Double, right: Swift.Double) -> Swift.Bool
public typealias AUValue = Swift.Float
public typealias MIDIByte = Swift.UInt8
public typealias MIDIWord = Swift.UInt16
public typealias MIDINoteNumber = Swift.UInt8
public typealias MIDIVelocity = Swift.UInt8
public typealias MIDIChannel = Swift.UInt8
public typealias SampleIndex = Swift.UInt32
public let noteOnByte: AudioKit.MIDIByte
public let noteOffByte: AudioKit.MIDIByte
public typealias FloatChannelData = [[Swift.Float]]
public typealias CVoidCallback = @convention(block) () -> Swift.Void
public typealias CMIDICallback = @convention(block) (AudioKit.MIDIByte, AudioKit.MIDIByte, AudioKit.MIDIByte) -> Swift.Void
extension AudioUnitParameterOptions {
  public static let `default`: AudioToolbox.AudioUnitParameterOptions
}
extension CGRect {
  public init(size: CoreGraphics.CGSize)
  public init(width: CoreGraphics.CGFloat, height: CoreGraphics.CGFloat)
  public init(width: Swift.Int, height: Swift.Int)
}
public func fourCC(_ string: Swift.String) -> Swift.UInt32
extension Float {
  public func normalized(from range: Swift.ClosedRange<AudioKit.AUValue>, taper: AudioKit.AUValue = 1) -> AudioKit.AUValue
  public func denormalized(to range: Swift.ClosedRange<AudioKit.AUValue>, taper: AudioKit.AUValue = 1) -> AudioKit.AUValue
}
extension Int {
  public func midiNoteToFrequency(_ aRef: AudioKit.AUValue = 440.0) -> AudioKit.AUValue
}
extension UInt8 {
  public func midiNoteToFrequency(_ aRef: AudioKit.AUValue = 440.0) -> AudioKit.AUValue
}
extension Float {
  public func midiNoteToFrequency(_ aRef: AudioKit.AUValue = 440.0) -> AudioKit.AUValue
}
extension Int {
  public func frequencyToMIDINote(_ aRef: AudioKit.AUValue = 440.0) -> AudioKit.AUValue
}
extension Float {
  public func frequencyToMIDINote(_ aRef: AudioKit.AUValue = 440.0) -> AudioKit.AUValue
}
extension RangeReplaceableCollection where Self.Element : Swift.ExpressibleByIntegerLiteral {
  public init(zeros count: Swift.Int)
}
extension ClosedRange {
  public func clamp(_ value: Bound) -> Bound
}
extension AUParameter {
  @nonobjc convenience public init(identifier: Swift.String, name: Swift.String, address: AudioToolbox.AUParameterAddress, range: Swift.ClosedRange<AudioKit.AUValue>, unit: AudioToolbox.AudioUnitParameterUnit, flags: AudioToolbox.AudioUnitParameterOptions)
}
public protocol Occupiable {
  var isEmpty: Swift.Bool { get }
  var isNotEmpty: Swift.Bool { get }
}
extension Occupiable {
  public var isNotEmpty: Swift.Bool {
    get
  }
}
extension String : AudioKit.Occupiable {
}
extension Array : AudioKit.Occupiable {
}
extension Dictionary : AudioKit.Occupiable {
}
extension Set : AudioKit.Occupiable {
}
extension AVAudioSession.CategoryOptions : AudioKit.Occupiable {
}
extension Sequence where Self.Element : Swift.Equatable {
  @inline(__always) public func doesNotContain(_ member: Self.Element) -> Swift.Bool
}
extension String {
  public func titleCase() -> Swift.String
}
extension Double {
  public func mapped(from source: Swift.ClosedRange<Swift.Double> = 0...1.0, to target: Swift.ClosedRange<Swift.Double> = 0...1.0) -> Swift.Double
}
extension CGFloat {
  public func mapped(from source: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0, to target: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0) -> CoreGraphics.CGFloat
  public func mappedInverted(from source: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0, to target: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0) -> CoreGraphics.CGFloat
  public func mappedLog10(from source: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0, to target: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0) -> CoreGraphics.CGFloat
  public func mappedExp(from source: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0, to target: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0) -> CoreGraphics.CGFloat
}
extension Int {
  public func mapped(from source: Swift.ClosedRange<Swift.Int>, to target: Swift.ClosedRange<CoreGraphics.CGFloat> = 0...1.0) -> CoreGraphics.CGFloat
}
extension Array where Element == Swift.Float {
  public func downSample(to sampleCount: Swift.Int = 128) -> [Element]
}
public func loadAudioSignal(audioURL: Foundation.URL) -> (signal: [Swift.Float], rate: Swift.Double, frameCount: Swift.Int)?
@objc public class CallbackLoop : ObjectiveC.NSObject {
  public var duration: Swift.Double
  public var frequency: Swift.Double {
    get
    set
  }
  public init(every period: Swift.Double, handler: @escaping () -> Swift.Void)
  public init(frequency: Swift.Double, handler: @escaping () -> Swift.Void)
  public func start()
  public func stop()
  @objc deinit
  @objc override dynamic public init()
}
extension OSLog {
  public static let general: os.OSLog
  public static let settings: os.OSLog
  public static let midi: os.OSLog
  public static let fileHandling: os.OSLog
}
@inline(__always) public func Log(_ items: Any?..., log: os.OSLog = OSLog.general, type: os.OSLogType = .info, file: Swift.String = #file, function: Swift.String = #function, line: Swift.Int = #line)
@propertyWrapper final public class ThreadLockedAccessor<T> {
  public init(wrappedValue value: T)
  final public var wrappedValue: T {
    get
    set
  }
  final public func mutate(_ closure: (inout T) -> Swift.Void)
  @objc deinit
}
@objc @_inheritsConvenienceInitializers public class BluetoothMIDIButton : UIKit.UIButton {
  public func centerPopupIn(view: UIKit.UIView)
  @objc override dynamic public func touchesEnded(_ touches: Swift.Set<UIKit.UITouch>, with event: UIKit.UIEvent?)
  @objc deinit
  @objc override dynamic public init(frame: CoreGraphics.CGRect)
  @objc required dynamic public init?(coder: Foundation.NSCoder)
}
public enum MIDIControl : AudioKit.MIDIByte {
  case modulationWheel
  case breathControl
  case footControl
  case portamento
  case dataEntry
  case mainVolume
  case balance
  case pan
  case expression
  case damperOnOff
  case portamentoOnOff
  case sustenutoOnOff
  case softPedalOnOff
  case soundVariation
  case resonance
  case releaseTime
  case attackTime
  case cutoff
  case soundControl6
  case soundControl7
  case soundControl8
  case soundControl9
  case soundControl10
  case gpButton1
  case gpButton2
  case gpButton3
  case gpButton4
  case reverbLevel
  case tremoloLevel
  case chorusLevel
  case celesteLevel
  case phaserLevel
  case dataEntryPlus
  case dataEntryMinus
  case NrpnLsb
  case NrpnMsb
  case RpnLsb
  case RpnMsb
  case allSoundsOff
  case allControllersOff
  case localControlOnOff
  case allNotesOff
  case omniModeOff
  case omniModeOn
  case monoOperation
  case polyOperation
  case cc0
  case cc3
  case cc9
  case cc12
  case cc13
  case cc14
  case cc15
  case cc16
  case cc17
  case cc18
  case cc19
  case cc20
  case cc21
  case cc22
  case cc23
  case cc24
  case cc25
  case cc26
  case cc27
  case cc28
  case cc29
  case cc30
  case cc31
  case cc32
  case modulationWheelLsb
  case breathControllerLsb
  case footControlLsb
  case portamentoLsb
  case dataEntryLsb
  case mainVolumeLsb
  case balanceLsb
  case panLsb
  case expressionLsb
  case effectControl1Lsb
  case effectControl2Lsb
  public typealias RawValue = AudioKit.MIDIByte
  public init?(rawValue: AudioKit.MIDIByte)
  public var rawValue: AudioKit.MIDIByte {
    get
  }
}
public enum MIDICustomMetaEventType : AudioKit.MIDIByte {
  case sequenceNumber
  case textEvent
  case copyright
  case trackName
  case instrumentName
  case lyric
  case marker
  case cuePoint
  case programName
  case devicePortName
  case metaEvent10
  case metaEvent12
  case channelPrefix
  case midiPort
  case endOfTrack
  case setTempo
  case smtpeOffset
  case timeSignature
  case keySignature
  case sequencerSpecificMetaEvent
  public var description: Swift.String {
    get
  }
  public typealias RawValue = AudioKit.MIDIByte
  public init?(rawValue: AudioKit.MIDIByte)
  public var rawValue: AudioKit.MIDIByte {
    get
  }
}
public struct MIDICustomMetaEvent : AudioKit.MIDIMessage {
  public var positionInBeats: Swift.Double?
  public init?(data: [AudioKit.MIDIByte])
  public let data: [AudioKit.MIDIByte]
  public let type: AudioKit.MIDICustomMetaEventType
  public let length: Swift.Int
  public var description: Swift.String {
    get
  }
  public var name: Swift.String? {
    get
  }
}
public protocol MIDIMessage {
  var data: [AudioKit.MIDIByte] { get }
  var description: Swift.String { get }
}
public struct MIDIStatus : AudioKit.MIDIMessage {
  public var data: [AudioKit.MIDIByte] {
    get
  }
  public var byte: AudioKit.MIDIByte
  public init(type: AudioKit.MIDIStatusType, channel: AudioKit.MIDIChannel)
  public init(command: AudioKit.MIDISystemCommand)
  public init?(byte: AudioKit.MIDIByte)
  public var type: AudioKit.MIDIStatusType? {
    get
  }
  public var channel: AudioKit.MIDIChannel {
    get
  }
  public var description: Swift.String {
    get
  }
  public var length: Swift.Int {
    get
  }
}
public enum MIDIStatusType : Swift.Int {
  case noteOff
  case noteOn
  case polyphonicAftertouch
  case controllerChange
  case programChange
  case channelAftertouch
  case pitchWheel
  public static func from(byte: AudioKit.MIDIByte) -> AudioKit.MIDIStatusType?
  public var length: Swift.Int {
    get
  }
  public var description: Swift.String {
    get
  }
  public typealias RawValue = Swift.Int
  public init?(rawValue: Swift.Int)
  public var rawValue: Swift.Int {
    get
  }
}
public enum MIDISystemCommand : AudioKit.MIDIByte, AudioKit.MIDIMessage {
  case sysEx
  case timeCodeQuarterFrame
  case songPosition
  case songSelect
  case tuneRequest
  case sysExEnd
  case clock
  case start
  case `continue`
  case stop
  case activeSensing
  case sysReset
  public var description: Swift.String {
    get
  }
  public var byte: AudioKit.MIDIByte {
    get
  }
  public var data: [AudioKit.MIDIByte] {
    get
  }
  public typealias RawValue = AudioKit.MIDIByte
  public var rawValue: AudioKit.MIDIByte {
    get
  }
  public init?(rawValue: AudioKit.MIDIByte)
}
public enum MIDISystemCommandType {
  case systemRealtime
  case systemCommon
  case systemExclusive
  public static func == (a: AudioKit.MIDISystemCommandType, b: AudioKit.MIDISystemCommandType) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public protocol MIDIBeatObserver {
  func preparePlay(continue: Swift.Bool)
  func startFirstBeat(continue: Swift.Bool)
  func stopSRT()
  func receivedBeatEvent(beat: Swift.UInt64)
  func receivedQuantum(time: CoreMIDI.MIDITimeStamp, quarterNote: AudioKit.MIDIByte, beat: Swift.UInt64, quantum: Swift.UInt64)
  func receivedQuarterNoteBeat(quarterNote: AudioKit.MIDIByte)
}
extension MIDIBeatObserver {
  public func preparePlay(continue: Swift.Bool)
  public func startFirstBeat(continue: Swift.Bool)
  public func stopSRT()
  public func receivedBeatEvent(beat: Swift.UInt64)
  public func receivedQuantum(time: CoreMIDI.MIDITimeStamp, quarterNote: AudioKit.MIDIByte, beat: Swift.UInt64, quantum: Swift.UInt64)
  public func receivedQuarterNoteBeat(quarterNote: AudioKit.MIDIByte)
  public func isEqualTo(_ listener: AudioKit.MIDIBeatObserver) -> Swift.Bool
}
@objc @_hasMissingDesignatedInitializers public class MIDIClockListener : ObjectiveC.NSObject {
  public var quarterNoteQuantumCounter: AudioKit.MIDIByte
  public var quantumCounter: Swift.UInt64
  public var sppMIDIBeatCounter: Swift.UInt64
  public var sppMIDIBeatQuantumCounter: AudioKit.MIDIByte
  public var fourCount: AudioKit.MIDIByte
  @objc deinit
  @objc override dynamic public init()
}
extension MIDIClockListener {
  public func addObserver(_ observer: AudioKit.MIDIBeatObserver)
  public func removeObserver(_ observer: AudioKit.MIDIBeatObserver)
  public func removeAllObservers()
}
extension MIDIClockListener : AudioKit.MIDIBeatObserver {
}
extension MIDIClockListener : AudioKit.MIDITempoObserver {
  public func midiClockFollowerMode()
  public func midiClockLeaderEnabled()
}
extension MIDIClockListener : AudioKit.MIDISystemRealTimeObserver {
  public func stopSRT(listener: AudioKit.MIDISystemRealTimeListener)
  public func startSRT(listener: AudioKit.MIDISystemRealTimeListener)
  public func continueSRT(listener: AudioKit.MIDISystemRealTimeListener)
}
@objc public class MIDIMonoPolyListener : ObjectiveC.NSObject {
  public init(mono: Swift.Bool = true)
  @objc deinit
  @objc override dynamic public init()
}
extension MIDIMonoPolyListener : AudioKit.MIDIListener {
  public func receivedMIDIController(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func monoPolyChanged()
  public func receivedMIDINoteOn(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDINoteOff(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIAftertouch(noteNumber: AudioKit.MIDINoteNumber, pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIAftertouch(_ pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIPitchWheel(_ pitchWheelValue: AudioKit.MIDIWord, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIProgramChange(_ program: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDISystemCommand(_ data: [AudioKit.MIDIByte], portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDISetupChange()
  public func receivedMIDIPropertyChange(propertyChangeInfo: CoreMIDI.MIDIObjectPropertyChangeNotification)
  public func receivedMIDINotification(notification: CoreMIDI.MIDINotification)
}
public protocol ObserverProtocol {
  func isEqualTo(_ listener: AudioKit.ObserverProtocol) -> Swift.Bool
}
@objc public class MIDIOMNIListener : ObjectiveC.NSObject {
  public init(omni: Swift.Bool = true)
  @objc deinit
  @objc override dynamic public init()
}
extension MIDIOMNIListener : AudioKit.MIDIListener {
  public func receivedMIDINoteOn(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDINoteOff(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIController(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIAftertouch(noteNumber: AudioKit.MIDINoteNumber, pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIAftertouch(_ pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIPitchWheel(_ pitchWheelValue: AudioKit.MIDIWord, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIProgramChange(_ program: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDISystemCommand(_ data: [AudioKit.MIDIByte], portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDISetupChange()
  public func receivedMIDIPropertyChange(propertyChangeInfo: CoreMIDI.MIDIObjectPropertyChangeNotification)
  public func receivedMIDINotification(notification: CoreMIDI.MIDINotification)
  public func omniStateChange()
}
@objc @_inheritsConvenienceInitializers open class MIDISystemRealTimeListener : ObjectiveC.NSObject {
  public enum SRTState {
    case stopped
    case playing
    case paused
    public static func == (a: AudioKit.MIDISystemRealTimeListener.SRTState, b: AudioKit.MIDISystemRealTimeListener.SRTState) -> Swift.Bool
    public var hashValue: Swift.Int {
      get
    }
    public func hash(into hasher: inout Swift.Hasher)
  }
  @objc deinit
  @objc override dynamic public init()
}
extension MIDISystemRealTimeListener : AudioKit.MIDIListener {
  public func receivedMIDISystemCommand(_ data: [AudioKit.MIDIByte], portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDINoteOn(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDINoteOff(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIController(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIAftertouch(noteNumber: AudioKit.MIDINoteNumber, pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIAftertouch(_ pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIPitchWheel(_ pitchWheelValue: AudioKit.MIDIWord, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIProgramChange(_ program: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDISetupChange()
  public func receivedMIDIPropertyChange(propertyChangeInfo: CoreMIDI.MIDIObjectPropertyChangeNotification)
  public func receivedMIDINotification(notification: CoreMIDI.MIDINotification)
}
extension MIDISystemRealTimeListener {
  public func addObserver(_ observer: AudioKit.MIDISystemRealTimeObserver)
  public func removeObserver(_ observer: AudioKit.MIDISystemRealTimeObserver)
  public func removeAllObservers()
}
public protocol MIDISystemRealTimeObserver {
  func startSRT(listener: AudioKit.MIDISystemRealTimeListener)
  func stopSRT(listener: AudioKit.MIDISystemRealTimeListener)
  func continueSRT(listener: AudioKit.MIDISystemRealTimeListener)
}
extension MIDISystemRealTimeObserver {
  public func isEqualTo(_ listener: AudioKit.MIDISystemRealTimeObserver) -> Swift.Bool
}
public typealias BPMType = Foundation.TimeInterval
@objc public class MIDITempoListener : ObjectiveC.NSObject {
  public var clockListener: AudioKit.MIDIClockListener?
  public var srtListener: AudioKit.MIDISystemRealTimeListener
  public var tempoString: Swift.String
  public var tempo: Swift.Double
  public var isIncomingClockActive: Swift.Bool
  public init(smoothing: Swift.Float64 = 0.8, bpmHistoryLimit: Swift.Int = 3)
  @objc deinit
  @objc override dynamic public init()
}
extension MIDITempoListener {
  public func analyze()
  public func resetClockEventsLeavingOne()
  public func resetClockEventsLeavingHalf()
  public func resetClockEventsLeavingNone()
}
extension MIDITempoListener : AudioKit.MIDIListener {
  public func receivedMIDISystemCommand(_ data: [AudioKit.MIDIByte], portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDINoteOn(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDINoteOff(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIController(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIAftertouch(noteNumber: AudioKit.MIDINoteNumber, pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIAftertouch(_ pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIPitchWheel(_ pitchWheelValue: AudioKit.MIDIWord, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDIProgramChange(_ program: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public func receivedMIDISetupChange()
  public func receivedMIDIPropertyChange(propertyChangeInfo: CoreMIDI.MIDIObjectPropertyChangeNotification)
  public func receivedMIDINotification(notification: CoreMIDI.MIDINotification)
}
extension MIDITempoListener {
  public func addObserver(_ observer: AudioKit.MIDITempoObserver)
  public func removeObserver(_ observer: AudioKit.MIDITempoObserver)
  public func removeAllObservers()
}
public protocol MIDITempoObserver {
  func midiClockLeaderMode()
  func midiClockLeaderEnabled()
  func receivedTempo(bpm: AudioKit.BPMType, label: Swift.String)
}
extension MIDITempoObserver {
  public func midiClockLeaderMode()
  public func midiClockLeaderEnabled()
  public func receivedTempo(bpm: AudioKit.BPMType, label: Swift.String)
  public func isEqualTo(_ listener: AudioKit.MIDITempoObserver) -> Swift.Bool
}
extension UInt8 {
  public var lowBit: AudioKit.MIDIByte {
    get
  }
  public var highBit: AudioKit.MIDIByte {
    get
  }
  public var hex: Swift.String {
    get
  }
}
public enum MIDITimeFormat : Swift.Int {
  case ticksPerBeat
  case framesPerSecond
  public typealias RawValue = Swift.Int
  public init?(rawValue: Swift.Int)
  public var rawValue: Swift.Int {
    get
  }
}
extension MIDI {
  public func addListener(_ listener: AudioKit.MIDIListener)
  public func removeListener(_ listener: AudioKit.MIDIListener)
  public func clearListeners()
}
extension MIDI {
  public func addTransformer(_ transformer: AudioKit.MIDITransformer)
  public func removeTransformer(_ transformer: AudioKit.MIDITransformer)
  public func clearTransformers()
}
extension MIDI {
  public var inputUIDs: [CoreMIDI.MIDIUniqueID] {
    get
  }
  public var inputNames: [Swift.String] {
    get
  }
  public func inputName(for inputUid: CoreMIDI.MIDIUniqueID) -> Swift.String?
  public func uidForInputAtIndex(_ inputIndex: Swift.Int = 0) -> CoreMIDI.MIDIUniqueID
  public func openInput(name: Swift.String = "")
  public func openInput(index inputIndex: Swift.Int)
  public func openInput(uid inputUID: CoreMIDI.MIDIUniqueID)
  @available(*, deprecated, message: "Try to not use names any more because they are not unique across devices")
  public func closeInput(name: Swift.String)
  public func closeInput()
  public func closeInput(index inputIndex: Swift.Int)
  public func closeInput(uid inputUID: CoreMIDI.MIDIUniqueID)
  public func closeAllInputs()
}
extension MIDI {
  public var destinationUIDs: [CoreMIDI.MIDIUniqueID] {
    get
  }
  public var destinationNames: [Swift.String] {
    get
  }
  public func destinationName(for destUid: CoreMIDI.MIDIUniqueID) -> Swift.String
  public func uidForDestinationAtIndex(_ outputIndex: Swift.Int = 0) -> CoreMIDI.MIDIUniqueID
  @available(*, deprecated, message: "Try to not use names any more because they are not unique across devices")
  public func openOutput(name: Swift.String)
  public func openOutput()
  public func openOutput(index outputIndex: Swift.Int)
  public func openOutput(uid outputUid: CoreMIDI.MIDIUniqueID)
  public func closeOutput(name: Swift.String = "")
  public func closeOutput(index outputIndex: Swift.Int)
  public func closeOutput(uid outputUid: CoreMIDI.MIDIUniqueID)
  public func sendMessage(_ data: [AudioKit.MIDIByte], offset: CoreMIDI.MIDITimeStamp = 0, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
  public func clearEndpoints()
  public func sendEvent(_ event: AudioKit.MIDIEvent, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
  public func sendNoteOnMessage(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel = 0, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
  public func sendNoteOffMessage(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel = 0, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
  public func sendControllerMessage(_ control: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel = 0, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
  public func sendPitchBendMessage(value: Swift.UInt16, channel: AudioKit.MIDIChannel = 0, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
  public func sendNoteOnMessageWithTime(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel = 0, time: CoreMIDI.MIDITimeStamp = 0, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
  public func sendNoteOffMessageWithTime(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel = 0, time: CoreMIDI.MIDITimeStamp = 0, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
  public func sendMessageWithTime(_ data: [AudioKit.MIDIByte], time: CoreMIDI.MIDITimeStamp, endpointsUIDs: [CoreMIDI.MIDIUniqueID]? = nil, virtualOutputPorts: [CoreMIDI.MIDIPortRef]? = nil)
}
extension MIDI {
  public func createVirtualPorts(numberOfPort: Swift.Int = 1, _ uniqueIDs: [Swift.Int32]? = nil, names: [Swift.String]? = nil)
  public func createVirtualInputPorts(numberOfPort: Swift.Int = 1, _ uniqueIDs: [Swift.Int32]? = nil, names: [Swift.String]? = nil)
  public func createVirtualOutputPorts(numberOfPort: Swift.Int = 1, _ uniqueIDs: [Swift.Int32]? = nil, names: [Swift.String]? = nil)
  public func destroyVirtualPorts()
  @discardableResult
  public func destroyVirtualInputPort() -> Swift.Bool
  @discardableResult
  public func destroyVirtualOutputPort() -> Swift.Bool
}
public class MIDI {
  public static var sharedInstance: AudioKit.MIDI
  public var client: CoreMIDI.MIDIClientRef
  public var inputPorts: [CoreMIDI.MIDIUniqueID : CoreMIDI.MIDIPortRef]
  public var virtualInputs: [CoreMIDI.MIDIPortRef]
  public var outputPort: CoreMIDI.MIDIPortRef
  public var virtualOutputs: [CoreMIDI.MIDIPortRef]
  public var endpoints: [CoreMIDI.MIDIUniqueID : CoreMIDI.MIDIEndpointRef]
  public var listeners: [AudioKit.MIDIListener]
  public var transformers: [AudioKit.MIDITransformer]
  public init()
  @objc deinit
}
open class MIDICallbackInstrument : AudioKit.MIDIInstrument {
  open var callback: AudioKit.MIDICallback?
  public init(midiInputName: Swift.String = "AudioKit Callback Instrument", callback: AudioKit.MIDICallback? = nil)
  override open func start(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  override open func stop(noteNumber: AudioKit.MIDINoteNumber, channel: AudioKit.MIDIChannel, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  override open func receivedMIDIController(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  override open func receivedMIDIAftertouch(noteNumber: AudioKit.MIDINoteNumber, pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  override open func receivedMIDIAftertouch(_ pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  override open func receivedMIDIPitchWheel(_ pitchWheelValue: AudioKit.MIDIWord, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  @objc deinit
  override public init(midiInputName: Swift.String? = super)
}
public struct EndpointInfo : Swift.Hashable, Swift.Codable {
  public var name: Swift.String
  public var displayName: Swift.String
  public var model: Swift.String
  public var manufacturer: Swift.String
  public var image: Swift.String
  public var driverOwner: Swift.String
  public var midiUniqueID: CoreMIDI.MIDIUniqueID
  public var midiEndpointRef: CoreMIDI.MIDIEndpointRef
  public var midiPortRef: CoreMIDI.MIDIPortRef?
  public static func == (lhs: AudioKit.EndpointInfo, rhs: AudioKit.EndpointInfo) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public init(name: Swift.String, displayName: Swift.String, model: Swift.String, manufacturer: Swift.String, image: Swift.String, driverOwner: Swift.String, midiUniqueID: CoreMIDI.MIDIUniqueID, midiEndpointRef: CoreMIDI.MIDIEndpointRef, midiPortRef: CoreMIDI.MIDIPortRef? = nil)
  public init(from decoder: Swift.Decoder) throws
  public var hashValue: Swift.Int {
    get
  }
  public func encode(to encoder: Swift.Encoder) throws
}
extension MIDI {
  public var destinationInfos: [AudioKit.EndpointInfo] {
    get
  }
  public var inputInfos: [AudioKit.EndpointInfo] {
    get
  }
}
public struct MIDIEvent : AudioKit.MIDIMessage {
  public var data: [AudioKit.MIDIByte]
  public var positionInBeats: Swift.Double?
  public var offset: CoreMIDI.MIDITimeStamp?
  public var timeStamp: CoreMIDI.MIDITimeStamp?
  public var description: Swift.String {
    get
  }
  public var internalPackets: [[AudioKit.MIDIByte]] {
    get
  }
  public var length: Swift.Int {
    get
  }
  public var status: AudioKit.MIDIStatus? {
    get
  }
  public var command: AudioKit.MIDISystemCommand? {
    get
  }
  public var channel: AudioKit.MIDIChannel? {
    get
  }
  public var noteNumber: AudioKit.MIDINoteNumber? {
    get
  }
  public var pitchbendAmount: AudioKit.MIDIWord? {
    get
  }
  public init(packet: CoreMIDI.MIDIPacket)
  public init(data: [AudioKit.MIDIByte], timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  public init(noteOn noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel)
  public init(noteOff noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel)
  public init(programChange data: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel)
  public init(controllerChange controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel)
  public static func midiEventsFrom(packetListPointer: Swift.UnsafePointer<CoreMIDI.MIDIPacketList>) -> [AudioKit.MIDIEvent]
  public static func generateFrom(bluetoothData: [AudioKit.MIDIByte]) -> [AudioKit.MIDIEvent]
}
public struct MIDIFile {
  public var filename: Swift.String
  public var trackChunks: [AudioKit.MIDIFileTrackChunk] {
    get
  }
  public var tempoTrack: AudioKit.MIDIFileTempoTrack? {
    get
  }
  public var tracks: [AudioKit.MIDIFileTrack] {
    get
  }
  public var format: Swift.Int {
    get
  }
  public var numberOfTracks: Swift.Int {
    get
  }
  public var timeFormat: AudioKit.MIDITimeFormat? {
    get
  }
  public var ticksPerBeat: Swift.Int? {
    get
  }
  public var framesPerSecond: Swift.Int? {
    get
  }
  public var ticksPerFrame: Swift.Int? {
    get
  }
  public var timeDivision: Swift.UInt16 {
    get
  }
  public init(url: Foundation.URL)
  public init(path: Swift.String)
}
public protocol MIDIFileChunk {
  var rawData: [AudioKit.MIDIByte] { get }
  var typeData: [AudioKit.MIDIByte] { get }
  var lengthData: [AudioKit.MIDIByte] { get }
  var data: [AudioKit.MIDIByte] { get }
  init?(data: [AudioKit.MIDIByte])
}
extension MIDIFileChunk {
  public var isValid: Swift.Bool {
    get
  }
  public var isNotValid: Swift.Bool {
    get
  }
  public var isTypeValid: Swift.Bool {
    get
  }
  public var isLengthValid: Swift.Bool {
    get
  }
  public var length: Swift.Int {
    get
  }
  public var typeData: [AudioKit.MIDIByte] {
    get
  }
  public var lengthData: [AudioKit.MIDIByte] {
    get
  }
  public var data: [AudioKit.MIDIByte] {
    get
  }
  public var type: AudioKit.MIDIFileChunkType? {
    get
  }
  public var isHeader: Swift.Bool {
    get
  }
  public var isTrack: Swift.Bool {
    get
  }
}
public enum MIDIFileChunkType : Swift.String {
  case track
  case header
  public typealias RawValue = Swift.String
  public init?(rawValue: Swift.String)
  public var rawValue: Swift.String {
    get
  }
}
public struct MIDIFileChunkEvent {
}
public struct MIDIFileTempoTrack {
  public let track: AudioKit.MIDIFileTrack
  public var length: Swift.Double {
    get
  }
  public var name: Swift.String? {
    get
  }
  public var events: [AudioKit.MIDIEvent] {
    get
  }
  public var metaEvents: [AudioKit.MIDICustomMetaEvent] {
    get
  }
  public var tempoData: [AudioKit.MIDIByte]
  public var tempo: Swift.Float {
    get
  }
}
public struct MIDIFileTrack {
  public var channelEvents: [AudioKit.MIDIEvent] {
    get
  }
  public var events: [AudioKit.MIDIEvent] {
    get
  }
  public var metaEvents: [AudioKit.MIDICustomMetaEvent] {
    get
  }
  public var length: Swift.Double {
    get
  }
  public var name: Swift.String? {
    get
  }
}
public struct MIDIFileTrackChunk : AudioKit.MIDIFileChunk {
  public let rawData: [AudioKit.MIDIByte]
  public init?(data: [AudioKit.MIDIByte])
  public var chunkEvents: [AudioKit.MIDIFileChunkEvent] {
    get
  }
}
public class MIDINoteDuration {
  public var noteStartTime: Swift.Double
  public var noteEndTime: Swift.Double
  public var noteDuration: Swift.Double
  public var noteNumber: Swift.Int
  public var noteNumberMap: Swift.Int
  public var noteRange: Swift.Int
  public init(noteOnPosition: Swift.Double, noteOffPosition: Swift.Double, noteNumber: Swift.Int)
  @objc deinit
}
public class MIDIFileTrackNoteMap {
  final public let midiTrack: AudioKit.MIDIFileTrack!
  final public let midiFile: AudioKit.MIDIFile!
  final public let trackNumber: Swift.Int!
  public var loNote: Swift.Int {
    get
  }
  public var hiNote: Swift.Int {
    get
  }
  public var noteRange: Swift.Int {
    get
  }
  public var endOfTrack: Swift.Double {
    get
  }
  public var noteList: [AudioKit.MIDINoteDuration] {
    get
  }
  public init(midiFile: AudioKit.MIDIFile, trackNumber: Swift.Int)
  @objc deinit
}
open class MIDIInstrument : AudioKit.Node, AudioKit.MIDIListener, AudioKit.NamedNode {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  open var midiIn: CoreMIDI.MIDIEndpointRef
  open var name: Swift.String
  open var mpeActiveNotes: [(note: AudioKit.MIDINoteNumber, channel: AudioKit.MIDIChannel)]
  public init(midiInputName: Swift.String? = nil)
  open func enableMIDI(_ midiClient: CoreMIDI.MIDIClientRef = MIDI.sharedInstance.client, name: Swift.String? = nil)
  open func receivedMIDINoteOn(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDINoteOff(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDIController(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDIAftertouch(noteNumber: AudioKit.MIDINoteNumber, pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDIAftertouch(_ pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDIPitchWheel(_ pitchWheelValue: AudioKit.MIDIWord, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDIProgramChange(_ program: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDISystemCommand(_ data: [AudioKit.MIDIByte], portID: CoreMIDI.MIDIUniqueID? = nil, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDISetupChange()
  open func receivedMIDIPropertyChange(propertyChangeInfo: CoreMIDI.MIDIObjectPropertyChangeNotification)
  open func receivedMIDINotification(notification: CoreMIDI.MIDINotification)
  open func start(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func stop(noteNumber: AudioKit.MIDINoteNumber, channel: AudioKit.MIDIChannel, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  open func receivedMIDIProgramChange(_ program: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, timeStamp: CoreMIDI.MIDITimeStamp? = nil)
  @objc deinit
}
public protocol MIDIListener {
  func receivedMIDINoteOn(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID?, timeStamp: CoreMIDI.MIDITimeStamp?)
  func receivedMIDINoteOff(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID?, timeStamp: CoreMIDI.MIDITimeStamp?)
  func receivedMIDIController(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID?, timeStamp: CoreMIDI.MIDITimeStamp?)
  func receivedMIDIAftertouch(noteNumber: AudioKit.MIDINoteNumber, pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID?, timeStamp: CoreMIDI.MIDITimeStamp?)
  func receivedMIDIAftertouch(_ pressure: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID?, timeStamp: CoreMIDI.MIDITimeStamp?)
  func receivedMIDIPitchWheel(_ pitchWheelValue: AudioKit.MIDIWord, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID?, timeStamp: CoreMIDI.MIDITimeStamp?)
  func receivedMIDIProgramChange(_ program: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel, portID: CoreMIDI.MIDIUniqueID?, timeStamp: CoreMIDI.MIDITimeStamp?)
  func receivedMIDISystemCommand(_ data: [AudioKit.MIDIByte], portID: CoreMIDI.MIDIUniqueID?, timeStamp: CoreMIDI.MIDITimeStamp?)
  func receivedMIDISetupChange()
  func receivedMIDIPropertyChange(propertyChangeInfo: CoreMIDI.MIDIObjectPropertyChangeNotification)
  func receivedMIDINotification(notification: CoreMIDI.MIDINotification)
}
extension MIDIListener {
  public func isEqualTo(_ listener: AudioKit.MIDIListener) -> Swift.Bool
}
public struct MIDINoteData : Swift.CustomStringConvertible, Swift.Equatable {
  public var noteNumber: AudioKit.MIDINoteNumber
  public var velocity: AudioKit.MIDIVelocity
  public var channel: AudioKit.MIDIChannel
  public var duration: AudioKit.Duration
  public var position: AudioKit.Duration
  public init(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel, duration: AudioKit.Duration, position: AudioKit.Duration)
  public var description: Swift.String {
    get
  }
  public static func == (a: AudioKit.MIDINoteData, b: AudioKit.MIDINoteData) -> Swift.Bool
}
extension AVAudioSequencer : Swift.Collection {
  public typealias Element = AVFoundation.AVMusicTrack
  public typealias Index = Swift.Int
  public var startIndex: AVFoundation.AVAudioSequencer.Index {
    get
  }
  public var endIndex: AVFoundation.AVAudioSequencer.Index {
    get
  }
  public subscript(index: AVFoundation.AVAudioSequencer.Index) -> AVFoundation.AVAudioSequencer.Element {
    get
  }
  public func index(after index: AVFoundation.AVAudioSequencer.Index) -> AVFoundation.AVAudioSequencer.Index
  public func rewind()
  public typealias Iterator = Swift.IndexingIterator<AVFoundation.AVAudioSequencer>
  public typealias SubSequence = Swift.Slice<AVFoundation.AVAudioSequencer>
  public typealias Indices = Swift.DefaultIndices<AVFoundation.AVAudioSequencer>
}
@objc public class MIDIPlayer : AVFoundation.AVAudioSequencer {
  public var tempo: Swift.Double
  public var loopEnabled: Swift.Bool
  public init(audioEngine: AVFoundation.AVAudioEngine, filename: Swift.String)
  public func sequence(from data: Foundation.Data)
  public func toggleLoop()
  public func enableLooping()
  public func enableLooping(_ loopLength: AudioKit.Duration)
  public func disableLooping()
  public var length: AudioKit.Duration {
    get
    set
  }
  public func play()
  public func setGlobalAVAudioUnitOutput(_ audioUnit: AVFoundation.AVAudioUnit)
  public var currentPosition: AudioKit.Duration {
    get
  }
  public var currentRelativePosition: AudioKit.Duration {
    get
  }
  public func loadMIDIFile(_ filename: Swift.String)
  public func setGlobalMIDIOutput(_ midiEndpoint: CoreMIDI.MIDIEndpointRef)
  @objc deinit
  @objc override dynamic public init()
  @objc override dynamic public init(audioEngine engine: AVFoundation.AVAudioEngine)
}
open class MIDISampler : AudioKit.AppleSampler, AudioKit.NamedNode {
  open var midiIn: CoreMIDI.MIDIEndpointRef
  open var name: Swift.String
  public init(name midiOutputName: Swift.String? = nil)
  public func enableMIDI(_ midiClient: CoreMIDI.MIDIClientRef = MIDI.sharedInstance.client, name: Swift.String? = nil)
  public func receivedMIDINoteOn(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel) throws
  public func midiCC(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, channel: AudioKit.MIDIChannel)
  override open func play(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel)
  override open func stop(noteNumber: AudioKit.MIDINoteNumber, channel: AudioKit.MIDIChannel)
  public func destroyEndpoint()
  @objc deinit
  override public init(file: Swift.String? = super)
}
public protocol MIDITransformer {
  func transform(eventList: [AudioKit.MIDIEvent]) -> [AudioKit.MIDIEvent]
}
extension MIDITransformer {
  public func transform(eventList: [AudioKit.MIDIEvent]) -> [AudioKit.MIDIEvent]
  public func isEqualTo(_ transformer: AudioKit.MIDITransformer) -> Swift.Bool
}
extension MIDIPacket : Swift.Sequence {
  public func makeIterator() -> Swift.AnyIterator<AudioKit.MIDIEvent>
  public typealias Element = AudioKit.MIDIEvent
  public typealias Iterator = Swift.AnyIterator<AudioKit.MIDIEvent>
}
extension MIDIPacketList : Swift.Sequence {
  public typealias Element = CoreMIDI.MIDIPacket
  public var count: Swift.UInt32 {
    get
  }
  public func makeIterator() -> Swift.AnyIterator<CoreMIDI.MIDIPacketList.Element>
  public typealias Iterator = Swift.AnyIterator<CoreMIDI.MIDIPacketList.Element>
}
@_hasMissingDesignatedInitializers public class MIDIHelper {
  public static func convertTo16Bit(msb: AudioKit.MIDIByte, lsb: AudioKit.MIDIByte) -> Swift.UInt16
  public static func convertTo32Bit(msb: AudioKit.MIDIByte, data1: AudioKit.MIDIByte, data2: AudioKit.MIDIByte, lsb: AudioKit.MIDIByte) -> Swift.UInt32
  public static func convertToString(bytes: [AudioKit.MIDIByte]) -> Swift.String
  public static func convertToASCII(bytes: [AudioKit.MIDIByte]) -> Swift.String?
  @objc deinit
}
public struct MIDISysExMessage : AudioKit.MIDIMessage {
  public let data: [AudioKit.MIDIByte]
  public let length: Swift.Int
  public var description: Swift.String {
    get
  }
  public init?(bytes: [AudioKit.MIDIByte])
}
@objc open class MIDITimeout : ObjectiveC.NSObject {
  public typealias ActionClosureType = () -> Swift.Void
  public init(timeoutInterval time: Foundation.TimeInterval, onMainThread: Swift.Bool = true, success: @escaping AudioKit.MIDITimeout.ActionClosureType, timeout: @escaping AudioKit.MIDITimeout.ActionClosureType)
  @objc deinit
  public func perform(_ block: () -> Swift.Void)
  public func succeed()
  @objc override dynamic public init()
}
public struct MIDIVariableLengthQuantity {
  public let data: [AudioKit.MIDIByte]
  public var length: Swift.Int {
    get
  }
  public var quantity: Swift.UInt32 {
    get
  }
  public init?(fromBytes data: Swift.ArraySlice<AudioKit.MIDIByte>)
  public init?(fromBytes data: [AudioKit.MIDIByte])
  public static func read(bytes: [AudioKit.MIDIByte]) -> (Swift.Int, Swift.UInt32)
}
public typealias MIDICallback = (AudioKit.MIDIByte, AudioKit.MIDIByte, AudioKit.MIDIByte) -> Swift.Void
open class CallbackInstrument : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public init(midiCallback: AudioKit.MIDICallback? = nil)
  @objc deinit
}
public class Delay : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let dryWetMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($dryWetMix) public var dryWetMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $dryWetMix: AudioKit.NodeParameter {
    get
    set
  }
  public static let timeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($time) public var time: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $time: AudioKit.NodeParameter {
    get
    set
  }
  public static let feedbackDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($feedback) public var feedback: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $feedback: AudioKit.NodeParameter {
    get
    set
  }
  public static let lowPassCutoffDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($lowPassCutoff) public var lowPassCutoff: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $lowPassCutoff: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, time: AudioKit.AUValue = timeDef.defaultValue, feedback: AudioKit.AUValue = feedbackDef.defaultValue, lowPassCutoff: AudioKit.AUValue = lowPassCutoffDef.defaultValue, dryWetMix: AudioKit.AUValue = dryWetMixDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class StereoDelay : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let timeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($time) public var time: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $time: AudioKit.NodeParameter {
    get
    set
  }
  public static let feedbackDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($feedback) public var feedback: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $feedback: AudioKit.NodeParameter {
    get
    set
  }
  public static let dryWetMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($dryWetMix) public var dryWetMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $dryWetMix: AudioKit.NodeParameter {
    get
    set
  }
  public static let pingPongDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pingPong) public var pingPong: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pingPong: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, time: AudioKit.AUValue = timeDef.defaultValue, feedback: AudioKit.AUValue = feedbackDef.defaultValue, dryWetMix: AudioKit.AUValue = dryWetMixDef.defaultValue, pingPong: Swift.Bool = (dryWetMixDef.defaultValue == 1.0), maximumDelayTime: AudioKit.AUValue = 2.0)
  @objc deinit
}
public class VariableDelay : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let timeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($time) public var time: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $time: AudioKit.NodeParameter {
    get
    set
  }
  public static let feedbackDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($feedback) public var feedback: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $feedback: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, time: AudioKit.AUValue = timeDef.defaultValue, feedback: AudioKit.AUValue = feedbackDef.defaultValue, maximumTime: AudioKit.AUValue = 5)
  @objc deinit
}
public class BitCrusher : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let bitDepthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($bitDepth) public var bitDepth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $bitDepth: AudioKit.NodeParameter {
    get
    set
  }
  public static let sampleRateDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($sampleRate) public var sampleRate: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $sampleRate: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, bitDepth: AudioKit.AUValue = bitDepthDef.defaultValue, sampleRate: AudioKit.AUValue = sampleRateDef.defaultValue)
  @objc deinit
}
public class Clipper : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let limitDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($limit) public var limit: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $limit: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, limit: AudioKit.AUValue = limitDef.defaultValue)
  @objc deinit
}
public class Decimator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let decimationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decimation) public var decimation: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decimation: AudioKit.NodeParameter {
    get
    set
  }
  public static let roundingDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($rounding) public var rounding: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $rounding: AudioKit.NodeParameter {
    get
    set
  }
  public static let finalMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($finalMix) public var finalMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $finalMix: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, decimation: AudioKit.AUValue = decimationDef.defaultValue, rounding: AudioKit.AUValue = roundingDef.defaultValue, finalMix: AudioKit.AUValue = finalMixDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class DiodeClipper : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let gainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($gain) public var gain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $gain: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue, gain: AudioKit.AUValue = gainDef.defaultValue)
  @objc deinit
}
public class Distortion : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let delayDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($delay) public var delay: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $delay: AudioKit.NodeParameter {
    get
    set
  }
  public static let decayDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decay) public var decay: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decay: AudioKit.NodeParameter {
    get
    set
  }
  public static let delayMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($delayMix) public var delayMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $delayMix: AudioKit.NodeParameter {
    get
    set
  }
  public static let ringModFreq1Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ringModFreq1) public var ringModFreq1: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ringModFreq1: AudioKit.NodeParameter {
    get
    set
  }
  public static let ringModFreq2Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ringModFreq2) public var ringModFreq2: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ringModFreq2: AudioKit.NodeParameter {
    get
    set
  }
  public static let ringModBalanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ringModBalance) public var ringModBalance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ringModBalance: AudioKit.NodeParameter {
    get
    set
  }
  public static let ringModMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ringModMix) public var ringModMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ringModMix: AudioKit.NodeParameter {
    get
    set
  }
  public static let decimationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decimation) public var decimation: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decimation: AudioKit.NodeParameter {
    get
    set
  }
  public static let roundingDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($rounding) public var rounding: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $rounding: AudioKit.NodeParameter {
    get
    set
  }
  public static let decimationMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decimationMix) public var decimationMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decimationMix: AudioKit.NodeParameter {
    get
    set
  }
  public static let linearTermDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($linearTerm) public var linearTerm: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $linearTerm: AudioKit.NodeParameter {
    get
    set
  }
  public static let squaredTermDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($squaredTerm) public var squaredTerm: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $squaredTerm: AudioKit.NodeParameter {
    get
    set
  }
  public static let cubicTermDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cubicTerm) public var cubicTerm: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cubicTerm: AudioKit.NodeParameter {
    get
    set
  }
  public static let polynomialMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($polynomialMix) public var polynomialMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $polynomialMix: AudioKit.NodeParameter {
    get
    set
  }
  public static let softClipGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($softClipGain) public var softClipGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $softClipGain: AudioKit.NodeParameter {
    get
    set
  }
  public static let finalMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($finalMix) public var finalMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $finalMix: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, delay: AudioKit.AUValue = delayDef.defaultValue, decay: AudioKit.AUValue = decayDef.defaultValue, delayMix: AudioKit.AUValue = delayMixDef.defaultValue, ringModFreq1: AudioKit.AUValue = ringModFreq1Def.defaultValue, ringModFreq2: AudioKit.AUValue = ringModFreq2Def.defaultValue, ringModBalance: AudioKit.AUValue = ringModBalanceDef.defaultValue, ringModMix: AudioKit.AUValue = ringModMixDef.defaultValue, decimation: AudioKit.AUValue = decimationDef.defaultValue, rounding: AudioKit.AUValue = roundingDef.defaultValue, decimationMix: AudioKit.AUValue = decimationMixDef.defaultValue, linearTerm: AudioKit.AUValue = linearTermDef.defaultValue, squaredTerm: AudioKit.AUValue = squaredTermDef.defaultValue, cubicTerm: AudioKit.AUValue = cubicTermDef.defaultValue, polynomialMix: AudioKit.AUValue = polynomialMixDef.defaultValue, softClipGain: AudioKit.AUValue = softClipGainDef.defaultValue, finalMix: AudioKit.AUValue = finalMixDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class RingModulator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let ringModFreq1Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ringModFreq1) public var ringModFreq1: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ringModFreq1: AudioKit.NodeParameter {
    get
    set
  }
  public static let ringModFreq2Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ringModFreq2) public var ringModFreq2: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ringModFreq2: AudioKit.NodeParameter {
    get
    set
  }
  public static let ringModBalanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ringModBalance) public var ringModBalance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ringModBalance: AudioKit.NodeParameter {
    get
    set
  }
  public static let finalMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($finalMix) public var finalMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $finalMix: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, ringModFreq1: AudioKit.AUValue = ringModFreq1Def.defaultValue, ringModFreq2: AudioKit.AUValue = ringModFreq2Def.defaultValue, ringModBalance: AudioKit.AUValue = ringModBalanceDef.defaultValue, finalMix: AudioKit.AUValue = finalMixDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class TanhDistortion : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let pregainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pregain) public var pregain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pregain: AudioKit.NodeParameter {
    get
    set
  }
  public static let postgainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($postgain) public var postgain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $postgain: AudioKit.NodeParameter {
    get
    set
  }
  public static let positiveShapeParameterDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($positiveShapeParameter) public var positiveShapeParameter: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $positiveShapeParameter: AudioKit.NodeParameter {
    get
    set
  }
  public static let negativeShapeParameterDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($negativeShapeParameter) public var negativeShapeParameter: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $negativeShapeParameter: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, pregain: AudioKit.AUValue = pregainDef.defaultValue, postgain: AudioKit.AUValue = postgainDef.defaultValue, positiveShapeParameter: AudioKit.AUValue = positiveShapeParameterDef.defaultValue, negativeShapeParameter: AudioKit.AUValue = negativeShapeParameterDef.defaultValue)
  @objc deinit
}
public class Compressor : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let thresholdDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($threshold) public var threshold: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $threshold: AudioKit.NodeParameter {
    get
    set
  }
  public static let headRoomDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($headRoom) public var headRoom: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $headRoom: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackTime) public var attackTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseTime) public var releaseTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let masterGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($masterGain) public var masterGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $masterGain: AudioKit.NodeParameter {
    get
    set
  }
  public var compressionAmount: AudioKit.AUValue {
    get
  }
  public var inputAmplitude: AudioKit.AUValue {
    get
  }
  public var outputAmplitude: AudioKit.AUValue {
    get
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, threshold: AudioKit.AUValue = thresholdDef.defaultValue, headRoom: AudioKit.AUValue = headRoomDef.defaultValue, attackTime: AudioKit.AUValue = attackTimeDef.defaultValue, releaseTime: AudioKit.AUValue = releaseTimeDef.defaultValue, masterGain: AudioKit.AUValue = masterGainDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class DynamicRangeCompressor : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let ratioDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ratio) public var ratio: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ratio: AudioKit.NodeParameter {
    get
    set
  }
  public static let thresholdDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($threshold) public var threshold: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $threshold: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackDuration) public var attackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseDuration) public var releaseDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseDuration: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, ratio: AudioKit.AUValue = ratioDef.defaultValue, threshold: AudioKit.AUValue = thresholdDef.defaultValue, attackDuration: AudioKit.AUValue = attackDurationDef.defaultValue, releaseDuration: AudioKit.AUValue = releaseDurationDef.defaultValue)
  @objc deinit
}
public class DynamicsProcessor : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let thresholdDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($threshold) public var threshold: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $threshold: AudioKit.NodeParameter {
    get
    set
  }
  public static let headRoomDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($headRoom) public var headRoom: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $headRoom: AudioKit.NodeParameter {
    get
    set
  }
  public static let expansionRatioDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($expansionRatio) public var expansionRatio: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $expansionRatio: AudioKit.NodeParameter {
    get
    set
  }
  public static let expansionThresholdDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($expansionThreshold) public var expansionThreshold: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $expansionThreshold: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackTime) public var attackTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseTime) public var releaseTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let masterGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($masterGain) public var masterGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $masterGain: AudioKit.NodeParameter {
    get
    set
  }
  public var compressionAmount: AudioKit.AUValue {
    get
  }
  public var inputAmplitude: AudioKit.AUValue {
    get
  }
  public var outputAmplitude: AudioKit.AUValue {
    get
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, threshold: AudioKit.AUValue = thresholdDef.defaultValue, headRoom: AudioKit.AUValue = headRoomDef.defaultValue, expansionRatio: AudioKit.AUValue = expansionRatioDef.defaultValue, expansionThreshold: AudioKit.AUValue = expansionThresholdDef.defaultValue, attackTime: AudioKit.AUValue = attackTimeDef.defaultValue, releaseTime: AudioKit.AUValue = releaseTimeDef.defaultValue, masterGain: AudioKit.AUValue = masterGainDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class Expander : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let expansionRatioDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($expansionRatio) public var expansionRatio: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $expansionRatio: AudioKit.NodeParameter {
    get
    set
  }
  public static let expansionThresholdDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($expansionThreshold) public var expansionThreshold: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $expansionThreshold: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackTime) public var attackTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseTime) public var releaseTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let masterGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($masterGain) public var masterGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $masterGain: AudioKit.NodeParameter {
    get
    set
  }
  public var compressionAmount: AudioKit.AUValue {
    get
  }
  public var inputAmplitude: AudioKit.AUValue {
    get
  }
  public var outputAmplitude: AudioKit.AUValue {
    get
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, expansionRatio: AudioKit.AUValue = expansionRatioDef.defaultValue, expansionThreshold: AudioKit.AUValue = expansionThresholdDef.defaultValue, attackTime: AudioKit.AUValue = attackTimeDef.defaultValue, releaseTime: AudioKit.AUValue = releaseTimeDef.defaultValue, masterGain: AudioKit.AUValue = masterGainDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class PeakLimiter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let attackTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackTime) public var attackTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let decayTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decayTime) public var decayTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decayTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let preGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($preGain) public var preGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $preGain: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, attackTime: AudioKit.AUValue = attackTimeDef.defaultValue, decayTime: AudioKit.AUValue = decayTimeDef.defaultValue, preGain: AudioKit.AUValue = preGainDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class TransientShaper : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let inputAmountDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($inputAmount) public var inputAmount: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $inputAmount: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackAmountDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackAmount) public var attackAmount: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackAmount: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseAmountDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseAmount) public var releaseAmount: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseAmount: AudioKit.NodeParameter {
    get
    set
  }
  public static let outputAmountDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($outputAmount) public var outputAmount: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $outputAmount: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, inputAmount: AudioKit.AUValue = inputAmountDef.defaultValue, attackAmount: AudioKit.AUValue = attackAmountDef.defaultValue, releaseAmount: AudioKit.AUValue = releaseAmountDef.defaultValue, outputAmount: AudioKit.AUValue = outputAmountDef.defaultValue)
  @objc deinit
}
public class AmplitudeEnvelope : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let attackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackDuration) public var attackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let decayDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decayDuration) public var decayDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decayDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let sustainLevelDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($sustainLevel) public var sustainLevel: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $sustainLevel: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseDuration) public var releaseDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseDuration: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, attackDuration: AudioKit.AUValue = attackDurationDef.defaultValue, decayDuration: AudioKit.AUValue = decayDurationDef.defaultValue, sustainLevel: AudioKit.AUValue = sustainLevelDef.defaultValue, releaseDuration: AudioKit.AUValue = releaseDurationDef.defaultValue)
  @objc deinit
}
public class Tremolo : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let depthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($depth) public var depth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $depth: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, frequency: AudioKit.AUValue = frequencyDef.defaultValue, depth: AudioKit.AUValue = depthDef.defaultValue, waveform: AudioKit.Table = Table(.positiveSine))
  @objc deinit
}
public class BandPassButterworthFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let centerFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($centerFrequency) public var centerFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $centerFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let bandwidthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($bandwidth) public var bandwidth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $bandwidth: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, centerFrequency: AudioKit.AUValue = centerFrequencyDef.defaultValue, bandwidth: AudioKit.AUValue = bandwidthDef.defaultValue)
  @objc deinit
}
public class BandPassFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let centerFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($centerFrequency) public var centerFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $centerFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let bandwidthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($bandwidth) public var bandwidth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $bandwidth: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, centerFrequency: AudioKit.AUValue = centerFrequencyDef.defaultValue, bandwidth: AudioKit.AUValue = bandwidthDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class BandRejectButterworthFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let centerFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($centerFrequency) public var centerFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $centerFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let bandwidthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($bandwidth) public var bandwidth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $bandwidth: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, centerFrequency: AudioKit.AUValue = centerFrequencyDef.defaultValue, bandwidth: AudioKit.AUValue = bandwidthDef.defaultValue)
  @objc deinit
}
public class DCBlock : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public init(_ input: AudioKit.Node)
  @objc deinit
}
public class EqualizerFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let centerFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($centerFrequency) public var centerFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $centerFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let bandwidthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($bandwidth) public var bandwidth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $bandwidth: AudioKit.NodeParameter {
    get
    set
  }
  public static let gainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($gain) public var gain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $gain: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, centerFrequency: AudioKit.AUValue = centerFrequencyDef.defaultValue, bandwidth: AudioKit.AUValue = bandwidthDef.defaultValue, gain: AudioKit.AUValue = gainDef.defaultValue)
  @objc deinit
}
public class FormantFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let centerFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($centerFrequency) public var centerFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $centerFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackDuration) public var attackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let decayDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decayDuration) public var decayDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decayDuration: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, centerFrequency: AudioKit.AUValue = centerFrequencyDef.defaultValue, attackDuration: AudioKit.AUValue = attackDurationDef.defaultValue, decayDuration: AudioKit.AUValue = decayDurationDef.defaultValue)
  @objc deinit
}
public class HighPassButterworthFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue)
  @objc deinit
}
public class HighPassFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let resonanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($resonance) public var resonance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $resonance: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue, resonance: AudioKit.AUValue = resonanceDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class HighShelfFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let cutOffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutOffFrequency) public var cutOffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutOffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let gainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($gain) public var gain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $gain: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, cutOffFrequency: AudioKit.AUValue = cutOffFrequencyDef.defaultValue, gain: AudioKit.AUValue = gainDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class HighShelfParametricEqualizerFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let centerFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($centerFrequency) public var centerFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $centerFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let gainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($gain) public var gain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $gain: AudioKit.NodeParameter {
    get
    set
  }
  public static let qDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($q) public var q: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $q: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, centerFrequency: AudioKit.AUValue = centerFrequencyDef.defaultValue, gain: AudioKit.AUValue = gainDef.defaultValue, q: AudioKit.AUValue = qDef.defaultValue)
  @objc deinit
}
public class KorgLowPassFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let resonanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($resonance) public var resonance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $resonance: AudioKit.NodeParameter {
    get
    set
  }
  public static let saturationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($saturation) public var saturation: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $saturation: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue, resonance: AudioKit.AUValue = resonanceDef.defaultValue, saturation: AudioKit.AUValue = saturationDef.defaultValue)
  @objc deinit
}
public class LowPassButterworthFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue)
  @objc deinit
}
public class LowPassFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let resonanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($resonance) public var resonance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $resonance: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue, resonance: AudioKit.AUValue = resonanceDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class LowShelfFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let gainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($gain) public var gain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $gain: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue, gain: AudioKit.AUValue = gainDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class LowShelfParametricEqualizerFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let cornerFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cornerFrequency) public var cornerFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cornerFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let gainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($gain) public var gain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $gain: AudioKit.NodeParameter {
    get
    set
  }
  public static let qDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($q) public var q: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $q: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, cornerFrequency: AudioKit.AUValue = cornerFrequencyDef.defaultValue, gain: AudioKit.AUValue = gainDef.defaultValue, q: AudioKit.AUValue = qDef.defaultValue)
  @objc deinit
}
public class ModalResonanceFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let qualityFactorDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($qualityFactor) public var qualityFactor: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $qualityFactor: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, frequency: AudioKit.AUValue = frequencyDef.defaultValue, qualityFactor: AudioKit.AUValue = qualityFactorDef.defaultValue)
  @objc deinit
}
public class MoogLadder : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let resonanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($resonance) public var resonance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $resonance: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue, resonance: AudioKit.AUValue = resonanceDef.defaultValue)
  @objc deinit
}
public class ParametricEQ : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public static let centerFreqDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($centerFreq) public var centerFreq: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $centerFreq: AudioKit.NodeParameter {
    get
    set
  }
  public static let qDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($q) public var q: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $q: AudioKit.NodeParameter {
    get
    set
  }
  public static let gainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($gain) public var gain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $gain: AudioKit.NodeParameter {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, centerFreq: AudioKit.AUValue = centerFreqDef.defaultValue, q: AudioKit.AUValue = qDef.defaultValue, gain: AudioKit.AUValue = gainDef.defaultValue)
  public func start()
  public func stop()
  @objc deinit
}
public class PeakingParametricEqualizerFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let centerFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($centerFrequency) public var centerFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $centerFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let gainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($gain) public var gain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $gain: AudioKit.NodeParameter {
    get
    set
  }
  public static let qDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($q) public var q: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $q: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, centerFrequency: AudioKit.AUValue = centerFrequencyDef.defaultValue, gain: AudioKit.AUValue = gainDef.defaultValue, q: AudioKit.AUValue = qDef.defaultValue)
  @objc deinit
}
public class ResonantFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let bandwidthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($bandwidth) public var bandwidth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $bandwidth: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, frequency: AudioKit.AUValue = frequencyDef.defaultValue, bandwidth: AudioKit.AUValue = bandwidthDef.defaultValue)
  @objc deinit
}
public class RolandTB303Filter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let resonanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($resonance) public var resonance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $resonance: AudioKit.NodeParameter {
    get
    set
  }
  public static let distortionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($distortion) public var distortion: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $distortion: AudioKit.NodeParameter {
    get
    set
  }
  public static let resonanceAsymmetryDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($resonanceAsymmetry) public var resonanceAsymmetry: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $resonanceAsymmetry: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue, resonance: AudioKit.AUValue = resonanceDef.defaultValue, distortion: AudioKit.AUValue = distortionDef.defaultValue, resonanceAsymmetry: AudioKit.AUValue = resonanceAsymmetryDef.defaultValue)
  @objc deinit
}
public class StringResonator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let fundamentalFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($fundamentalFrequency) public var fundamentalFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $fundamentalFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let feedbackDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($feedback) public var feedback: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $feedback: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, fundamentalFrequency: AudioKit.AUValue = fundamentalFrequencyDef.defaultValue, feedback: AudioKit.AUValue = feedbackDef.defaultValue)
  @objc deinit
}
public class ThreePoleLowpassFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let distortionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($distortion) public var distortion: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $distortion: AudioKit.NodeParameter {
    get
    set
  }
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let resonanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($resonance) public var resonance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $resonance: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, distortion: AudioKit.AUValue = distortionDef.defaultValue, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue, resonance: AudioKit.AUValue = resonanceDef.defaultValue)
  @objc deinit
}
public class ToneComplementFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let halfPowerPointDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($halfPowerPoint) public var halfPowerPoint: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $halfPowerPoint: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, halfPowerPoint: AudioKit.AUValue = halfPowerPointDef.defaultValue)
  @objc deinit
}
public class ToneFilter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let halfPowerPointDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($halfPowerPoint) public var halfPowerPoint: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $halfPowerPoint: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, halfPowerPoint: AudioKit.AUValue = halfPowerPointDef.defaultValue)
  @objc deinit
}
public class AutoWah : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let wahDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($wah) public var wah: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $wah: AudioKit.NodeParameter {
    get
    set
  }
  public static let mixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($mix) public var mix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $mix: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, wah: AudioKit.AUValue = wahDef.defaultValue, mix: AudioKit.AUValue = mixDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue)
  @objc deinit
}
public class DynaRageCompressor : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let ratioDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($ratio) public var ratio: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $ratio: AudioKit.NodeParameter {
    get
    set
  }
  public static let thresholdDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($threshold) public var threshold: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $threshold: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackDuration) public var attackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseDuration) public var releaseDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let rageDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($rage) public var rage: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $rage: AudioKit.NodeParameter {
    get
    set
  }
  public static let rageEnabledDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($rageEnabled) public var rageEnabled: Swift.Bool {
    get
    set
    _modify
  }
  public var $rageEnabled: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, ratio: AudioKit.AUValue = ratioDef.defaultValue, threshold: AudioKit.AUValue = thresholdDef.defaultValue, attackDuration: AudioKit.AUValue = attackDurationDef.defaultValue, releaseDuration: AudioKit.AUValue = releaseDurationDef.defaultValue, rage: AudioKit.AUValue = rageDef.defaultValue, rageEnabled: Swift.Bool = rageEnabledDef.defaultValue == 1.0)
  @objc deinit
}
public class RhinoGuitarProcessor : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let preGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($preGain) public var preGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $preGain: AudioKit.NodeParameter {
    get
    set
  }
  public static let postGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($postGain) public var postGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $postGain: AudioKit.NodeParameter {
    get
    set
  }
  public static let lowGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($lowGain) public var lowGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $lowGain: AudioKit.NodeParameter {
    get
    set
  }
  public static let midGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($midGain) public var midGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $midGain: AudioKit.NodeParameter {
    get
    set
  }
  public static let highGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($highGain) public var highGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $highGain: AudioKit.NodeParameter {
    get
    set
  }
  public static let distortionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($distortion) public var distortion: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $distortion: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, preGain: AudioKit.AUValue = preGainDef.defaultValue, postGain: AudioKit.AUValue = postGainDef.defaultValue, lowGain: AudioKit.AUValue = lowGainDef.defaultValue, midGain: AudioKit.AUValue = midGainDef.defaultValue, highGain: AudioKit.AUValue = highGainDef.defaultValue, distortion: AudioKit.AUValue = distortionDef.defaultValue)
  @objc deinit
}
public class Chorus : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let depthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($depth) public var depth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $depth: AudioKit.NodeParameter {
    get
    set
  }
  public static let feedbackDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($feedback) public var feedback: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $feedback: AudioKit.NodeParameter {
    get
    set
  }
  public static let dryWetMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($dryWetMix) public var dryWetMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $dryWetMix: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, frequency: AudioKit.AUValue = frequencyDef.defaultValue, depth: AudioKit.AUValue = depthDef.defaultValue, feedback: AudioKit.AUValue = feedbackDef.defaultValue, dryWetMix: AudioKit.AUValue = dryWetMixDef.defaultValue)
  @objc deinit
}
public class Flanger : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let depthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($depth) public var depth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $depth: AudioKit.NodeParameter {
    get
    set
  }
  public static let feedbackDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($feedback) public var feedback: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $feedback: AudioKit.NodeParameter {
    get
    set
  }
  public static let dryWetMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($dryWetMix) public var dryWetMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $dryWetMix: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, frequency: AudioKit.AUValue = frequencyDef.defaultValue, depth: AudioKit.AUValue = depthDef.defaultValue, feedback: AudioKit.AUValue = feedbackDef.defaultValue, dryWetMix: AudioKit.AUValue = dryWetMixDef.defaultValue)
  @objc deinit
}
public class Phaser : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let notchMinimumFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($notchMinimumFrequency) public var notchMinimumFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $notchMinimumFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let notchMaximumFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($notchMaximumFrequency) public var notchMaximumFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $notchMaximumFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let notchWidthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($notchWidth) public var notchWidth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $notchWidth: AudioKit.NodeParameter {
    get
    set
  }
  public static let notchFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($notchFrequency) public var notchFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $notchFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let vibratoModeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($vibratoMode) public var vibratoMode: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $vibratoMode: AudioKit.NodeParameter {
    get
    set
  }
  public static let depthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($depth) public var depth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $depth: AudioKit.NodeParameter {
    get
    set
  }
  public static let feedbackDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($feedback) public var feedback: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $feedback: AudioKit.NodeParameter {
    get
    set
  }
  public static let invertedDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($inverted) public var inverted: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $inverted: AudioKit.NodeParameter {
    get
    set
  }
  public static let lfoBPMDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($lfoBPM) public var lfoBPM: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $lfoBPM: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, notchMinimumFrequency: AudioKit.AUValue = notchMinimumFrequencyDef.defaultValue, notchMaximumFrequency: AudioKit.AUValue = notchMaximumFrequencyDef.defaultValue, notchWidth: AudioKit.AUValue = notchWidthDef.defaultValue, notchFrequency: AudioKit.AUValue = notchFrequencyDef.defaultValue, vibratoMode: AudioKit.AUValue = vibratoModeDef.defaultValue, depth: AudioKit.AUValue = depthDef.defaultValue, feedback: AudioKit.AUValue = feedbackDef.defaultValue, inverted: AudioKit.AUValue = invertedDef.defaultValue, lfoBPM: AudioKit.AUValue = lfoBPMDef.defaultValue)
  @objc deinit
}
public class PitchShifter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let shiftDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($shift) public var shift: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $shift: AudioKit.NodeParameter {
    get
    set
  }
  public static let windowSizeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($windowSize) public var windowSize: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $windowSize: AudioKit.NodeParameter {
    get
    set
  }
  public static let crossfadeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($crossfade) public var crossfade: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $crossfade: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, shift: AudioKit.AUValue = shiftDef.defaultValue, windowSize: AudioKit.AUValue = windowSizeDef.defaultValue, crossfade: AudioKit.AUValue = crossfadeDef.defaultValue)
  @objc deinit
}
public class ChowningReverb : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public init(_ input: AudioKit.Node)
  @objc deinit
}
public class CombFilterReverb : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let reverbDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($reverbDuration) public var reverbDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $reverbDuration: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, reverbDuration: AudioKit.AUValue = reverbDurationDef.defaultValue, loopDuration: AudioKit.AUValue = 0.1)
  @objc deinit
}
public class Convolution : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public init(_ input: AudioKit.Node, impulseResponseFileURL: Foundation.URL, partitionLength: Swift.Int = 2_048)
  @objc deinit
}
public class CostelloReverb : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let feedbackDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($feedback) public var feedback: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $feedback: AudioKit.NodeParameter {
    get
    set
  }
  public static let cutoffFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($cutoffFrequency) public var cutoffFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $cutoffFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, feedback: AudioKit.AUValue = feedbackDef.defaultValue, cutoffFrequency: AudioKit.AUValue = cutoffFrequencyDef.defaultValue)
  @objc deinit
}
public class FlatFrequencyResponseReverb : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let reverbDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($reverbDuration) public var reverbDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $reverbDuration: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, reverbDuration: AudioKit.AUValue = reverbDurationDef.defaultValue, loopDuration: AudioKit.AUValue = 0.1)
  @objc deinit
}
public class Reverb : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public var dryWetMix: AudioKit.AUValue {
    get
    set
  }
  public var isStarted: Swift.Bool
  public init(_ input: AudioKit.Node, dryWetMix: AudioKit.AUValue = 0.5)
  public func loadFactoryPreset(_ preset: AVFoundation.AVAudioUnitReverbPreset)
  @objc deinit
}
public class ZitaReverb : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let predelayDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($predelay) public var predelay: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $predelay: AudioKit.NodeParameter {
    get
    set
  }
  public static let crossoverFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($crossoverFrequency) public var crossoverFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $crossoverFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let lowReleaseTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($lowReleaseTime) public var lowReleaseTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $lowReleaseTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let midReleaseTimeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($midReleaseTime) public var midReleaseTime: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $midReleaseTime: AudioKit.NodeParameter {
    get
    set
  }
  public static let dampingFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($dampingFrequency) public var dampingFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $dampingFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let equalizerFrequency1Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($equalizerFrequency1) public var equalizerFrequency1: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $equalizerFrequency1: AudioKit.NodeParameter {
    get
    set
  }
  public static let equalizerLevel1Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($equalizerLevel1) public var equalizerLevel1: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $equalizerLevel1: AudioKit.NodeParameter {
    get
    set
  }
  public static let equalizerFrequency2Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($equalizerFrequency2) public var equalizerFrequency2: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $equalizerFrequency2: AudioKit.NodeParameter {
    get
    set
  }
  public static let equalizerLevel2Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($equalizerLevel2) public var equalizerLevel2: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $equalizerLevel2: AudioKit.NodeParameter {
    get
    set
  }
  public static let dryWetMixDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($dryWetMix) public var dryWetMix: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $dryWetMix: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, predelay: AudioKit.AUValue = predelayDef.defaultValue, crossoverFrequency: AudioKit.AUValue = crossoverFrequencyDef.defaultValue, lowReleaseTime: AudioKit.AUValue = lowReleaseTimeDef.defaultValue, midReleaseTime: AudioKit.AUValue = midReleaseTimeDef.defaultValue, dampingFrequency: AudioKit.AUValue = dampingFrequencyDef.defaultValue, equalizerFrequency1: AudioKit.AUValue = equalizerFrequency1Def.defaultValue, equalizerLevel1: AudioKit.AUValue = equalizerLevel1Def.defaultValue, equalizerFrequency2: AudioKit.AUValue = equalizerFrequency2Def.defaultValue, equalizerLevel2: AudioKit.AUValue = equalizerLevel2Def.defaultValue, dryWetMix: AudioKit.AUValue = dryWetMixDef.defaultValue)
  @objc deinit
}
public class BrownianNoise : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public init(amplitude: AudioKit.AUValue = amplitudeDef.defaultValue)
  @objc deinit
}
public class PinkNoise : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public init(amplitude: AudioKit.AUValue = amplitudeDef.defaultValue)
  @objc deinit
}
public class WhiteNoise : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public init(amplitude: AudioKit.AUValue = amplitudeDef.defaultValue)
  @objc deinit
}
public class DynamicOscillator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public var wavetableUpdateHandler: ([Swift.Float]) -> Swift.Void
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningOffsetDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningOffset) public var detuningOffset: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningOffset: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningMultiplierDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningMultiplier) public var detuningMultiplier: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningMultiplier: AudioKit.NodeParameter {
    get
    set
  }
  public init(waveform: AudioKit.Table = Table(.sawtooth), frequency: AudioKit.AUValue = frequencyDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue, detuningOffset: AudioKit.AUValue = detuningOffsetDef.defaultValue, detuningMultiplier: AudioKit.AUValue = detuningMultiplierDef.defaultValue)
  public func setWaveTable(waveform: AudioKit.Table)
  public func getWavetableValues() -> [Swift.Float]
  @objc deinit
}
public class FMOscillator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let baseFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($baseFrequency) public var baseFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $baseFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let carrierMultiplierDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($carrierMultiplier) public var carrierMultiplier: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $carrierMultiplier: AudioKit.NodeParameter {
    get
    set
  }
  public static let modulatingMultiplierDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($modulatingMultiplier) public var modulatingMultiplier: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $modulatingMultiplier: AudioKit.NodeParameter {
    get
    set
  }
  public static let modulationIndexDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($modulationIndex) public var modulationIndex: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $modulationIndex: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public init(waveform: AudioKit.Table = Table(.sine), baseFrequency: AudioKit.AUValue = baseFrequencyDef.defaultValue, carrierMultiplier: AudioKit.AUValue = carrierMultiplierDef.defaultValue, modulatingMultiplier: AudioKit.AUValue = modulatingMultiplierDef.defaultValue, modulationIndex: AudioKit.AUValue = modulationIndexDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue)
  @objc deinit
}
public class MorphingOscillator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public static let indexDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($index) public var index: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $index: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningOffsetDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningOffset) public var detuningOffset: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningOffset: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningMultiplierDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningMultiplier) public var detuningMultiplier: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningMultiplier: AudioKit.NodeParameter {
    get
    set
  }
  public init(waveformArray: [AudioKit.Table] = [Table(.triangle), Table(.square), Table(.sine), Table(.sawtooth)], frequency: AudioKit.AUValue = frequencyDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue, index: AudioKit.AUValue = indexDef.defaultValue, detuningOffset: AudioKit.AUValue = detuningOffsetDef.defaultValue, detuningMultiplier: AudioKit.AUValue = detuningMultiplierDef.defaultValue)
  @objc deinit
}
public class Oscillator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningOffsetDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningOffset) public var detuningOffset: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningOffset: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningMultiplierDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningMultiplier) public var detuningMultiplier: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningMultiplier: AudioKit.NodeParameter {
    get
    set
  }
  public init(waveform: AudioKit.Table = Table(.sine), frequency: AudioKit.AUValue = frequencyDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue, detuningOffset: AudioKit.AUValue = detuningOffsetDef.defaultValue, detuningMultiplier: AudioKit.AUValue = detuningMultiplierDef.defaultValue)
  @objc deinit
}
public class PWMOscillator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public static let pulseWidthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pulseWidth) public var pulseWidth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pulseWidth: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningOffsetDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningOffset) public var detuningOffset: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningOffset: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningMultiplierDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningMultiplier) public var detuningMultiplier: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningMultiplier: AudioKit.NodeParameter {
    get
    set
  }
  public init(frequency: AudioKit.AUValue = frequencyDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue, pulseWidth: AudioKit.AUValue = pulseWidthDef.defaultValue, detuningOffset: AudioKit.AUValue = detuningOffsetDef.defaultValue, detuningMultiplier: AudioKit.AUValue = detuningMultiplierDef.defaultValue)
  @objc deinit
}
public class PhaseDistortionOscillator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public static let phaseDistortionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($phaseDistortion) public var phaseDistortion: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $phaseDistortion: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningOffsetDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningOffset) public var detuningOffset: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningOffset: AudioKit.NodeParameter {
    get
    set
  }
  public static let detuningMultiplierDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($detuningMultiplier) public var detuningMultiplier: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $detuningMultiplier: AudioKit.NodeParameter {
    get
    set
  }
  public init(waveform: AudioKit.Table = Table(.sine), frequency: AudioKit.AUValue = frequencyDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue, phaseDistortion: AudioKit.AUValue = phaseDistortionDef.defaultValue, detuningOffset: AudioKit.AUValue = detuningOffsetDef.defaultValue, detuningMultiplier: AudioKit.AUValue = detuningMultiplierDef.defaultValue)
  @objc deinit
}
public class Drip : AudioKit.Node, AudioKit.Triggerable {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let intensityDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($intensity) public var intensity: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $intensity: AudioKit.NodeParameter {
    get
    set
  }
  public static let dampingFactorDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($dampingFactor) public var dampingFactor: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $dampingFactor: AudioKit.NodeParameter {
    get
    set
  }
  public static let energyReturnDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($energyReturn) public var energyReturn: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $energyReturn: AudioKit.NodeParameter {
    get
    set
  }
  public static let mainResonantFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($mainResonantFrequency) public var mainResonantFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $mainResonantFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let firstResonantFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($firstResonantFrequency) public var firstResonantFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $firstResonantFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let secondResonantFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($secondResonantFrequency) public var secondResonantFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $secondResonantFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public init(intensity: AudioKit.AUValue = intensityDef.defaultValue, dampingFactor: AudioKit.AUValue = dampingFactorDef.defaultValue, energyReturn: AudioKit.AUValue = energyReturnDef.defaultValue, mainResonantFrequency: AudioKit.AUValue = mainResonantFrequencyDef.defaultValue, firstResonantFrequency: AudioKit.AUValue = firstResonantFrequencyDef.defaultValue, secondResonantFrequency: AudioKit.AUValue = secondResonantFrequencyDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue)
  @objc deinit
}
@_inheritsConvenienceInitializers public class SynthKick : AudioKit.MIDIInstrument {
  override public init(midiInputName: Swift.String? = nil)
  public func play(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel = 0)
  public func stop(noteNumber: AudioKit.MIDINoteNumber, channel: AudioKit.MIDIChannel = 0)
  @objc deinit
}
public class SynthSnare : AudioKit.MIDIInstrument {
  public init(duration: Swift.Double = 0.143, resonance: AudioKit.AUValue = 0.9)
  public func play(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel)
  public func stop(noteNumber: AudioKit.MIDINoteNumber, channel: AudioKit.MIDIChannel = 0)
  @objc deinit
  override public init(midiInputName: Swift.String? = super)
}
public class MetalBar : AudioKit.Node, AudioKit.Triggerable {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let leftBoundaryConditionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($leftBoundaryCondition) public var leftBoundaryCondition: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $leftBoundaryCondition: AudioKit.NodeParameter {
    get
    set
  }
  public static let rightBoundaryConditionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($rightBoundaryCondition) public var rightBoundaryCondition: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $rightBoundaryCondition: AudioKit.NodeParameter {
    get
    set
  }
  public static let decayDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decayDuration) public var decayDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decayDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let scanSpeedDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($scanSpeed) public var scanSpeed: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $scanSpeed: AudioKit.NodeParameter {
    get
    set
  }
  public static let positionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($position) public var position: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $position: AudioKit.NodeParameter {
    get
    set
  }
  public static let strikeVelocityDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($strikeVelocity) public var strikeVelocity: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $strikeVelocity: AudioKit.NodeParameter {
    get
    set
  }
  public static let strikeWidthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($strikeWidth) public var strikeWidth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $strikeWidth: AudioKit.NodeParameter {
    get
    set
  }
  public init(leftBoundaryCondition: AudioKit.AUValue = leftBoundaryConditionDef.defaultValue, rightBoundaryCondition: AudioKit.AUValue = rightBoundaryConditionDef.defaultValue, decayDuration: AudioKit.AUValue = decayDurationDef.defaultValue, scanSpeed: AudioKit.AUValue = scanSpeedDef.defaultValue, position: AudioKit.AUValue = positionDef.defaultValue, strikeVelocity: AudioKit.AUValue = strikeVelocityDef.defaultValue, strikeWidth: AudioKit.AUValue = strikeWidthDef.defaultValue, stiffness: AudioKit.AUValue = 3, highFrequencyDamping: AudioKit.AUValue = 0.001)
  @objc deinit
}
public class PluckedString : AudioKit.Node, AudioKit.Triggerable {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public init(frequency: AudioKit.AUValue = frequencyDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue, lowestFrequency: AudioKit.AUValue = 110)
  public func trigger(frequency: AudioKit.AUValue, amplitude: AudioKit.AUValue = 1)
  @objc deinit
}
public class STKBase : AudioKit.Node, AudioKit.MIDITriggerable {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public init(_ code: Swift.String)
  @objc deinit
}
public class Clarinet : AudioKit.STKBase {
  public init()
  @objc deinit
  override public init(_ code: Swift.String)
}
public class Flute : AudioKit.STKBase {
  public init()
  @objc deinit
  override public init(_ code: Swift.String)
}
public class MandolinString : AudioKit.STKBase {
  public init()
  @objc deinit
  override public init(_ code: Swift.String)
}
public class RhodesPianoKey : AudioKit.STKBase {
  public init()
  @objc deinit
  override public init(_ code: Swift.String)
}
public class Shaker : AudioKit.STKBase {
  public init()
  @objc deinit
  override public init(_ code: Swift.String)
}
public class TubularBells : AudioKit.STKBase {
  public init()
  @objc deinit
  override public init(_ code: Swift.String)
}
extension Shaker {
  public func trigger(type: AudioKit.ShakerType, amplitude: Swift.Double = 0.5)
}
public enum ShakerType : AudioKit.MIDIByte {
  case maraca
  case cabasa
  case sekere
  case tambourine
  case sleighBells
  case bambooChimes
  case sandPaper
  case sodaCan
  case sticks
  case crunch
  case bigRocks
  case littleRocks
  case nextMug
  case pennyInMug
  case nickleInMug
  case dimeInMug
  case quarterInMug
  case francInMug
  case pesoInMug
  case guiro
  case wrench
  case waterDrops
  case tunedBambooChimes
  public typealias RawValue = AudioKit.MIDIByte
  public init?(rawValue: AudioKit.MIDIByte)
  public var rawValue: AudioKit.MIDIByte {
    get
  }
}
public class VocalTract : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let tonguePositionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($tonguePosition) public var tonguePosition: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $tonguePosition: AudioKit.NodeParameter {
    get
    set
  }
  public static let tongueDiameterDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($tongueDiameter) public var tongueDiameter: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $tongueDiameter: AudioKit.NodeParameter {
    get
    set
  }
  public static let tensenessDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($tenseness) public var tenseness: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $tenseness: AudioKit.NodeParameter {
    get
    set
  }
  public static let nasalityDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($nasality) public var nasality: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $nasality: AudioKit.NodeParameter {
    get
    set
  }
  public init(frequency: AudioKit.AUValue = frequencyDef.defaultValue, tonguePosition: AudioKit.AUValue = tonguePositionDef.defaultValue, tongueDiameter: AudioKit.AUValue = tongueDiameterDef.defaultValue, tenseness: AudioKit.AUValue = tensenessDef.defaultValue, nasality: AudioKit.AUValue = nasalityDef.defaultValue)
  @objc deinit
}
public class Synth : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let masterVolumeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($masterVolume) public var masterVolume: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $masterVolume: AudioKit.NodeParameter {
    get
    set
  }
  public static let pitchBendDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pitchBend) public var pitchBend: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pitchBend: AudioKit.NodeParameter {
    get
    set
  }
  public static let vibratoDepthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($vibratoDepth) public var vibratoDepth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $vibratoDepth: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterCutoffDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterCutoff) public var filterCutoff: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterCutoff: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterStrengthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterStrength) public var filterStrength: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterStrength: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterResonanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterResonance) public var filterResonance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterResonance: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackDuration) public var attackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let decayDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decayDuration) public var decayDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decayDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let sustainLevelDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($sustainLevel) public var sustainLevel: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $sustainLevel: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseDuration) public var releaseDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterAttackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterAttackDuration) public var filterAttackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterAttackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterDecayDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterDecayDuration) public var filterDecayDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterDecayDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterSustainLevelDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterSustainLevel) public var filterSustainLevel: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterSustainLevel: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterReleaseDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterReleaseDuration) public var filterReleaseDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterReleaseDuration: AudioKit.NodeParameter {
    get
    set
  }
  public init(masterVolume: AudioKit.AUValue = masterVolumeDef.defaultValue, pitchBend: AudioKit.AUValue = pitchBendDef.defaultValue, vibratoDepth: AudioKit.AUValue = vibratoDepthDef.defaultValue, filterCutoff: AudioKit.AUValue = filterCutoffDef.defaultValue, filterStrength: AudioKit.AUValue = filterStrengthDef.defaultValue, filterResonance: AudioKit.AUValue = filterResonanceDef.defaultValue, attackDuration: AudioKit.AUValue = attackDurationDef.defaultValue, decayDuration: AudioKit.AUValue = decayDurationDef.defaultValue, sustainLevel: AudioKit.AUValue = sustainLevelDef.defaultValue, releaseDuration: AudioKit.AUValue = releaseDurationDef.defaultValue, filterEnable: Swift.Bool = false, filterAttackDuration: AudioKit.AUValue = filterAttackDurationDef.defaultValue, filterDecayDuration: AudioKit.AUValue = filterDecayDurationDef.defaultValue, filterSustainLevel: AudioKit.AUValue = filterSustainLevelDef.defaultValue, filterReleaseDuration: AudioKit.AUValue = filterReleaseDurationDef.defaultValue)
  public func play(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel = 0)
  public func stop(noteNumber: AudioKit.MIDINoteNumber, channel: AudioKit.MIDIChannel = 0)
  @objc deinit
}
public class AutoPanner : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let frequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($frequency) public var frequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $frequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let depthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($depth) public var depth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $depth: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, frequency: AudioKit.AUValue = frequencyDef.defaultValue, depth: AudioKit.AUValue = depthDef.defaultValue, waveform: AudioKit.Table = Table(.positiveSine))
  @objc deinit
}
public class Balancer : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public init(_ input: AudioKit.Node, comparator: AudioKit.Node)
  @objc deinit
}
public class DryWetMixer : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let balanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($balance) public var balance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $balance: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input1: AudioKit.Node, _ input2: AudioKit.Node, balance: AudioKit.AUValue = balanceDef.defaultValue)
  convenience public init(dry: AudioKit.Node, wet: AudioKit.Node, balance: AudioKit.AUValue = 0.5)
  @objc deinit
}
public class Fader : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  open var gain: AudioKit.AUValue {
    get
    set
  }
  public static let gainRange: Swift.ClosedRange<AudioKit.AUValue>
  public static let leftGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($leftGain) public var leftGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $leftGain: AudioKit.NodeParameter {
    get
    set
  }
  public static let rightGainDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($rightGain) public var rightGain: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $rightGain: AudioKit.NodeParameter {
    get
    set
  }
  public var dB: AudioKit.AUValue {
    get
    set
  }
  public static let flipStereoDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($flipStereo) public var flipStereo: Swift.Bool {
    get
    set
    _modify
  }
  public var $flipStereo: AudioKit.NodeParameter {
    get
    set
  }
  public static let mixToMonoDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($mixToMono) public var mixToMono: Swift.Bool {
    get
    set
    _modify
  }
  public var $mixToMono: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, gain: AudioKit.AUValue = 1)
  @objc deinit
  public func automateGain(events: [CAudioKit.AutomationEvent], startTime: AVFoundation.AVAudioTime? = nil)
  public func stopAutomation()
}
public class Mixer : AudioKit.Node, AudioKit.NamedNode {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  open var name: Swift.String
  public var volume: AudioKit.AUValue {
    get
    set
  }
  public var pan: AudioKit.AUValue {
    get
    set
  }
  public var isStarted: Swift.Bool {
    get
  }
  public init(volume: AudioKit.AUValue = 1.0, name: Swift.String? = nil)
  convenience public init(_ inputs: AudioKit.Node..., name: Swift.String? = nil)
  convenience public init(_ inputs: [AudioKit.Node], name: Swift.String? = nil)
  public func addInput(_ node: AudioKit.Node)
  public func hasInput(_ node: AudioKit.Node) -> Swift.Bool
  public func removeInput(_ node: AudioKit.Node)
  public func removeAllInputs()
  public func resizeInputBussesArray(requiredSize: Swift.Int) -> Swift.Int
  @objc deinit
}
public class Panner : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let panDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pan) public var pan: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pan: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, pan: AudioKit.AUValue = panDef.defaultValue)
  @objc deinit
}
public class StereoFieldLimiter : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let amountDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amount) public var amount: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amount: AudioKit.NodeParameter {
    get
    set
  }
  public init(_ input: AudioKit.Node, amount: AudioKit.AUValue = amountDef.defaultValue)
  @objc deinit
}
public protocol NamedNode : AudioKit.Node {
  var name: Swift.String { get set }
}
public protocol Triggerable {
  func trigger()
}
extension Node where Self : AudioKit.Triggerable {
  public func trigger()
}
public protocol MIDITriggerable {
  func trigger(note: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity)
}
extension Node where Self : AudioKit.MIDITriggerable {
  public func trigger(note: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity = 127)
}
extension Node {
  public var connectionTreeDescription: Swift.String {
    get
  }
}
public protocol Node : AnyObject {
  var connections: [AudioKit.Node] { get }
  var avAudioNode: AVFoundation.AVAudioNode { get }
}
extension Node {
  public func reset()
  public func scheduleMIDIEvent(event: AudioKit.MIDIEvent, offset: Swift.UInt64 = 0)
  public var isStarted: Swift.Bool {
    get
  }
  public func start()
  public func stop()
  public func play()
  public func bypass()
  public func setupParameters()
  public var au: AudioKit.AudioKitAU {
    get
  }
}
public func instantiate(generator code: Swift.String) -> AVFoundation.AVAudioNode
public func instantiate(instrument code: Swift.String) -> AVFoundation.AVAudioNode
public func instantiate(effect code: Swift.String) -> AVFoundation.AVAudioNode
public func instantiate(mixer code: Swift.String) -> AVFoundation.AVAudioNode
public struct NodeParameterDef {
  public var identifier: Swift.String
  public var name: Swift.String
  public var address: AudioToolbox.AUParameterAddress
  public var defaultValue: AudioKit.AUValue
  public var range: Swift.ClosedRange<AudioKit.AUValue>
  public var unit: AudioToolbox.AudioUnitParameterUnit
  public var flags: AudioToolbox.AudioUnitParameterOptions
  public init(identifier: Swift.String, name: Swift.String, address: AudioToolbox.AUParameterAddress, defaultValue: AudioKit.AUValue, range: Swift.ClosedRange<AudioKit.AUValue>, unit: AudioToolbox.AudioUnitParameterUnit, flags: AudioToolbox.AudioUnitParameterOptions = .default)
}
public class NodeParameter {
  public var parameter: AudioToolbox.AUParameter! {
    get
  }
  public var def: AudioKit.NodeParameterDef
  public var value: AudioKit.AUValue {
    get
    set
  }
  public var boolValue: Swift.Bool {
    get
    set
  }
  public var minValue: AudioKit.AUValue {
    get
  }
  public var maxValue: AudioKit.AUValue {
    get
  }
  public var range: Swift.ClosedRange<AudioKit.AUValue> {
    get
  }
  public init(_ def: AudioKit.NodeParameterDef)
  public func automate(events: [CAudioKit.AutomationEvent], startTime: AVFoundation.AVAudioTime? = nil)
  public func ramp(to value: AudioKit.AUValue, duration: Swift.Float)
  public func stopAutomation()
  public func recordAutomation(callback: @escaping (AudioToolbox.AUParameterAutomationEvent) -> Swift.Void)
  public func stopRecording()
  public func associate(with avAudioNode: AVFoundation.AVAudioNode)
  public func associate(with avAudioNode: AVFoundation.AVAudioNode, parameter: AudioToolbox.AUParameter)
  public func beginTouch(value: AudioKit.AUValue? = nil)
  public func endTouch(value: AudioKit.AUValue? = nil)
  @objc deinit
}
public protocol NodeParameterType {
  func toAUValue() -> AudioKit.AUValue
  init(_ value: AudioKit.AUValue)
}
extension Bool : AudioKit.NodeParameterType {
  public func toAUValue() -> AudioKit.AUValue
  public init(_ value: AudioKit.AUValue)
}
extension Float : AudioKit.NodeParameterType {
  public func toAUValue() -> AudioKit.AUValue
}
@propertyWrapper public struct Parameter<Value> where Value : AudioKit.NodeParameterType {
  public init(_ def: AudioKit.NodeParameterDef)
  public var wrappedValue: Value {
    get
    set
  }
  public var projectedValue: AudioKit.NodeParameter {
    get
    set
  }
}
extension AudioPlayer {
  @available(*, deprecated, renamed: "schedule(at:)")
  public func scheduleBuffer(_ buffer: AVFoundation.AVAudioPCMBuffer, at when: AVFoundation.AVAudioTime?, options: AVFoundation.AVAudioPlayerNodeBufferOptions = [])
  @available(*, deprecated, renamed: "schedule(at:)")
  public func scheduleBuffer(url: Foundation.URL, at when: AVFoundation.AVAudioTime?, options: AVFoundation.AVAudioPlayerNodeBufferOptions = [])
  @available(*, deprecated, renamed: "schedule(at:)")
  public func scheduleFile(_ file: AVFoundation.AVAudioFile, at when: AVFoundation.AVAudioTime?)
}
extension AudioPlayer {
  public func play(from startTime: Foundation.TimeInterval? = nil, to endTime: Foundation.TimeInterval? = nil, at when: AVFoundation.AVAudioTime? = nil, completionCallbackType: AVFoundation.AVAudioPlayerNodeCompletionCallbackType = .dataPlayedBack)
  public func pause()
  public func getCurrentTime() -> Foundation.TimeInterval
  public func seek(time: Foundation.TimeInterval)
}
extension AudioPlayer {
  public var isStarted: Swift.Bool {
    get
  }
  public func start()
  public func stop()
}
extension AudioPlayer {
  public func schedule(at when: AVFoundation.AVAudioTime? = nil, completionCallbackType: AVFoundation.AVAudioPlayerNodeCompletionCallbackType = .dataPlayedBack)
}
public class AudioPlayer : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var playerNode: AVFoundation.AVAudioPlayerNode {
    get
  }
  public var mixerNode: AVFoundation.AVAudioMixerNode {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public var volume: AudioKit.AUValue {
    get
    set
  }
  public var isPlaying: Swift.Bool {
    get
  }
  public var isPaused: Swift.Bool {
    get
  }
  public var isScheduled: Swift.Bool {
    get
  }
  public var isBuffered: Swift.Bool {
    get
    set
  }
  public var isReversed: Swift.Bool {
    get
    set
  }
  public var isLooping: Swift.Bool {
    get
    set
  }
  public var isSeeking: Swift.Bool {
    get
  }
  public var duration: Foundation.TimeInterval {
    get
  }
  public var completionHandler: AVFoundation.AVAudioNodeCompletionHandler?
  public var file: AVFoundation.AVAudioFile? {
    get
    set
  }
  public var buffer: AVFoundation.AVAudioPCMBuffer? {
    get
    set
  }
  public var editStartTime: Foundation.TimeInterval {
    get
    set
  }
  public var editEndTime: Foundation.TimeInterval {
    get
    set
  }
  public init()
  public init?(file: AVFoundation.AVAudioFile, buffered: Swift.Bool = false)
  convenience public init?(url: Foundation.URL, buffered: Swift.Bool = false)
  convenience public init?(buffer: AVFoundation.AVAudioPCMBuffer)
  @objc deinit
  public func load(url: Foundation.URL, buffered: Swift.Bool = false) throws
  public func load(file: AVFoundation.AVAudioFile, buffered: Swift.Bool = false) throws
  public func load(buffer: AVFoundation.AVAudioPCMBuffer)
}
extension AudioPlayer {
  public func makeInternalConnections()
}
public class PhaseLockedVocoder : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let positionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($position) public var position: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $position: AudioKit.NodeParameter {
    get
    set
  }
  public static let amplitudeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($amplitude) public var amplitude: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $amplitude: AudioKit.NodeParameter {
    get
    set
  }
  public static let pitchRatioDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pitchRatio) public var pitchRatio: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pitchRatio: AudioKit.NodeParameter {
    get
    set
  }
  public init(file: AVFoundation.AVAudioFile, position: AudioKit.AUValue = positionDef.defaultValue, amplitude: AudioKit.AUValue = amplitudeDef.defaultValue, pitchRatio: AudioKit.AUValue = pitchRatioDef.defaultValue)
  @objc deinit
}
open class AppleSampler : AudioKit.Node {
  public var internalAU: AudioToolbox.AUAudioUnit? {
    get
  }
  public var audioFiles: [AVFoundation.AVAudioFile] {
    get
    set
  }
  public var samplerUnit: AVFoundation.AVAudioUnitSampler
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode {
    get
  }
  public var tuning: AudioKit.AUValue {
    get
    set
  }
  public init(file: Swift.String? = nil)
  public func loadWav(_ file: Swift.String, in bundle: Foundation.Bundle = .main) throws
  public func loadEXS24(_ file: Swift.String) throws
  public func loadAudioFile(_ file: AVFoundation.AVAudioFile) throws
  public func loadAudioFiles(_ files: [AVFoundation.AVAudioFile]) throws
  public func loadPath(_ filePath: Swift.String) throws
  public var amplitude: AudioKit.AUValue {
    get
    set
  }
  public var volume: AudioKit.AUValue {
    get
    set
  }
  public var pan: AudioKit.AUValue {
    get
    set
  }
  open func play(noteNumber: AudioKit.MIDINoteNumber = 60, velocity: AudioKit.MIDIVelocity = 127, channel: AudioKit.MIDIChannel = 0)
  open func stop(noteNumber: AudioKit.MIDINoteNumber = 60, channel: AudioKit.MIDIChannel = 0)
  public func loadSoundFont(_ file: Swift.String, preset: Swift.Int, bank: Swift.Int, in bundle: Foundation.Bundle = .main) throws
  public func loadMelodicSoundFont(_ file: Swift.String, preset: Swift.Int, in bundle: Foundation.Bundle = .main) throws
  public func loadPercussiveSoundFont(_ file: Swift.String, preset: Swift.Int = 0, in bundle: Foundation.Bundle = .main) throws
  public func setPitchbend(amount: AudioKit.MIDIWord, channel: AudioKit.MIDIChannel)
  public func resetSampler()
  @objc deinit
}
@_hasMissingDesignatedInitializers public class PresetBuilder {
  public static func createAUPreset(dict: [Foundation.NSMutableDictionary], path: Swift.String, instrumentName: Swift.String, attack: Swift.Double? = 0, release: Swift.Double? = 0)
  public static func generateDictionary(rootNote: Swift.Int, filename: Swift.String, startNote: Swift.Int, endNote: Swift.Int) -> Foundation.NSMutableDictionary
  public static func buildInstrument(name: Swift.String = "Coded Instrument Name", connections: Swift.String = "", envelopes: Swift.String = "", filter: Swift.String = "", lfos: Swift.String = "", zones: Swift.String = "***ZONES***\n", filerefs: Swift.String = "***FILEREFS***\n", layers: Swift.String = "") -> Swift.String
  @objc deinit
}
public enum SampleTriggerMode : Swift.String {
  case Hold
  case Trigger
  case Loop
  case Repeat
  public typealias RawValue = Swift.String
  public init?(rawValue: Swift.String)
  public var rawValue: Swift.String {
    get
  }
}
extension Sampler {
  public func loadSFZ(url: Foundation.URL)
}
public class Sampler : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let masterVolumeDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($masterVolume) public var masterVolume: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $masterVolume: AudioKit.NodeParameter {
    get
    set
  }
  public static let pitchBendDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pitchBend) public var pitchBend: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pitchBend: AudioKit.NodeParameter {
    get
    set
  }
  public static let vibratoDepthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($vibratoDepth) public var vibratoDepth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $vibratoDepth: AudioKit.NodeParameter {
    get
    set
  }
  public static let vibratoFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($vibratoFrequency) public var vibratoFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $vibratoFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let voiceVibratoDepthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($voiceVibratoDepth) public var voiceVibratoDepth: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $voiceVibratoDepth: AudioKit.NodeParameter {
    get
    set
  }
  public static let voiceVibratoFrequencyDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($voiceVibratoFrequency) public var voiceVibratoFrequency: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $voiceVibratoFrequency: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterCutoffDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterCutoff) public var filterCutoff: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterCutoff: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterStrengthDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterStrength) public var filterStrength: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterStrength: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterResonanceDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterResonance) public var filterResonance: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterResonance: AudioKit.NodeParameter {
    get
    set
  }
  public static let glideRateDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($glideRate) public var glideRate: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $glideRate: AudioKit.NodeParameter {
    get
    set
  }
  public static let attackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($attackDuration) public var attackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $attackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let holdDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($holdDuration) public var holdDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $holdDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let decayDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($decayDuration) public var decayDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $decayDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let sustainLevelDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($sustainLevel) public var sustainLevel: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $sustainLevel: AudioKit.NodeParameter {
    get
    set
  }
  public static let releaseDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($releaseDuration) public var releaseDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $releaseDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterAttackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterAttackDuration) public var filterAttackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterAttackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterDecayDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterDecayDuration) public var filterDecayDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterDecayDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterSustainLevelDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterSustainLevel) public var filterSustainLevel: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterSustainLevel: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterReleaseDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterReleaseDuration) public var filterReleaseDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterReleaseDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let pitchAttackDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pitchAttackDuration) public var pitchAttackDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pitchAttackDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let pitchDecayDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pitchDecayDuration) public var pitchDecayDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pitchDecayDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let pitchSustainLevelDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pitchSustainLevel) public var pitchSustainLevel: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pitchSustainLevel: AudioKit.NodeParameter {
    get
    set
  }
  public static let pitchReleaseDurationDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pitchReleaseDuration) public var pitchReleaseDuration: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pitchReleaseDuration: AudioKit.NodeParameter {
    get
    set
  }
  public static let pitchADSRSemitonesDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($pitchADSRSemitones) public var pitchADSRSemitones: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $pitchADSRSemitones: AudioKit.NodeParameter {
    get
    set
  }
  public static let restartVoiceLFODef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($restartVoiceLFO) public var restartVoiceLFO: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $restartVoiceLFO: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterEnableDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterEnable) public var filterEnable: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterEnable: AudioKit.NodeParameter {
    get
    set
  }
  public static let loopThruReleaseDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($loopThruRelease) public var loopThruRelease: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $loopThruRelease: AudioKit.NodeParameter {
    get
    set
  }
  public static let isMonophonicDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($isMonophonic) public var isMonophonic: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $isMonophonic: AudioKit.NodeParameter {
    get
    set
  }
  public static let isLegatoDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($isLegato) public var isLegato: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $isLegato: AudioKit.NodeParameter {
    get
    set
  }
  public static let keyTrackingFractionDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($keyTrackingFraction) public var keyTrackingFraction: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $keyTrackingFraction: AudioKit.NodeParameter {
    get
    set
  }
  public static let filterEnvelopeVelocityScalingDef: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($filterEnvelopeVelocityScaling) public var filterEnvelopeVelocityScaling: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $filterEnvelopeVelocityScaling: AudioKit.NodeParameter {
    get
    set
  }
  public init()
  convenience public init(sampleDescriptor: CAudioKit.SampleDescriptor, file: AVFoundation.AVAudioFile)
  public typealias FileWithSampleDescriptor = (sampleDescriptor: CAudioKit.SampleDescriptor, file: AVFoundation.AVAudioFile)
  convenience public init(filesWithSampleDescriptors: [AudioKit.Sampler.FileWithSampleDescriptor])
  convenience public init(sfzURL: Foundation.URL)
  convenience public init(sfzPath: Swift.String, sfzFileName: Swift.String)
  public func stopAllVoices()
  public func restartVoices()
  public func loadRawSampleData(from sampleDataDescriptor: CAudioKit.SampleDataDescriptor)
  public func loadCompressedSampleFile(from sampleFileDescriptor: CAudioKit.SampleFileDescriptor)
  public func unloadAllSamples()
  public func setNoteFrequency(noteNumber: AudioKit.MIDINoteNumber, frequency: AudioKit.AUValue)
  public func buildSimpleKeyMap()
  public func buildKeyMap()
  public func setLoop(thruRelease: Swift.Bool)
  public func play(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, channel: AudioKit.MIDIChannel = 0)
  public func stop(noteNumber: AudioKit.MIDINoteNumber, channel: AudioKit.MIDIChannel = 0)
  public func silence(noteNumber: AudioKit.MIDINoteNumber)
  public func sustainPedal(pedalDown: Swift.Bool)
  @objc deinit
}
public class TimePitch : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public var rate: AudioKit.AUValue {
    get
    set
  }
  public var isStarted: Swift.Bool {
    get
  }
  public var pitch: AudioKit.AUValue {
    get
    set
  }
  public var overlap: AudioKit.AUValue {
    get
    set
  }
  public init(_ input: AudioKit.Node, rate: AudioKit.AUValue = 1.0, pitch: AudioKit.AUValue = 0.0, overlap: AudioKit.AUValue = 8.0)
  public func start()
  public func stop()
  @objc deinit
}
public class VariSpeed : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public var rate: AudioKit.AUValue {
    get
    set
  }
  public var isStarted: Swift.Bool {
    get
  }
  public init(_ input: AudioKit.Node, rate: AudioKit.AUValue = 1.0)
  public func start()
  public func stop()
  @objc deinit
}
extension ComputedParameter {
  public func delay(time: Swift.Double = 1.0, feedback: AudioKit.OperationParameter = 0.0) -> AudioKit.Operation
}
extension ComputedParameter {
  public func smoothDelay(time: AudioKit.OperationParameter = 1.0, feedback: AudioKit.OperationParameter = 0.0, samples: Swift.Int = 1_024, maximumDelayTime: Swift.Double = 5.0) -> AudioKit.Operation
}
extension ComputedParameter {
  public func variableDelay(time: AudioKit.OperationParameter = 1.0, feedback: AudioKit.OperationParameter = 0.0, maximumDelayTime: Swift.Double = 5.0) -> AudioKit.Operation
}
extension ComputedParameter {
  public func bitCrush(bitDepth: AudioKit.OperationParameter = 8, sampleRate: AudioKit.OperationParameter = 10_000) -> AudioKit.Operation
}
extension ComputedParameter {
  public func clip(_ limit: AudioKit.OperationParameter = 1.0) -> AudioKit.Operation
}
extension ComputedParameter {
  public func distort(pregain: AudioKit.OperationParameter = 2.0, postgain: AudioKit.OperationParameter = 0.5, positiveShapeParameter: AudioKit.OperationParameter = 0.0, negativeShapeParameter: AudioKit.OperationParameter = 0.0) -> AudioKit.Operation
}
extension ComputedParameter {
  public func autoWah(wah: AudioKit.OperationParameter = 0, amplitude: AudioKit.OperationParameter = 0.1) -> AudioKit.Operation
}
extension ComputedParameter {
  public func dcBlock() -> AudioKit.Operation
}
extension ComputedParameter {
  public func highPassButterworthFilter(cutoffFrequency: AudioKit.OperationParameter = 500) -> AudioKit.ComputedParameter
}
extension ComputedParameter {
  public func highPassFilter(halfPowerPoint: AudioKit.OperationParameter = 1_000) -> AudioKit.Operation
}
extension ComputedParameter {
  public func korgLowPassFilter(cutoffFrequency: AudioKit.OperationParameter = 1_000.0, resonance: AudioKit.OperationParameter = 1.0, saturation: AudioKit.OperationParameter = 0.0) -> AudioKit.Operation
}
extension ComputedParameter {
  public func lowPassButterworthFilter(cutoffFrequency: AudioKit.OperationParameter = 1_000) -> AudioKit.Operation
}
extension ComputedParameter {
  public func lowPassFilter(halfPowerPoint: AudioKit.OperationParameter = 1_000) -> AudioKit.Operation
}
extension ComputedParameter {
  public func modalResonanceFilter(frequency: AudioKit.OperationParameter = 500.0, qualityFactor: AudioKit.OperationParameter = 50.0) -> AudioKit.Operation
}
extension ComputedParameter {
  public func moogLadderFilter(cutoffFrequency: AudioKit.OperationParameter = 1_000, resonance: AudioKit.OperationParameter = 0.5) -> AudioKit.Operation
}
extension ComputedParameter {
  public func resonantFilter(frequency: AudioKit.OperationParameter = 4_000.0, bandwidth: AudioKit.OperationParameter = 1_000.0) -> AudioKit.Operation
}
extension ComputedParameter {
  public func stringResonator(frequency: AudioKit.OperationParameter = 100.0, feedback: AudioKit.OperationParameter = 0.95) -> AudioKit.Operation
}
extension ComputedParameter {
  public func threePoleLowPassFilter(distortion: AudioKit.OperationParameter = 0.5, cutoffFrequency: AudioKit.OperationParameter = 1_500, resonance: AudioKit.OperationParameter = 0.5) -> AudioKit.Operation
}
extension ComputedParameter {
  public func reverberateWithChowning() -> AudioKit.Operation
}
extension ComputedParameter {
  public func reverberateWithCombFilter(reverbDuration: AudioKit.OperationParameter = 1.0, loopDuration: AudioKit.OperationParameter = 0.1) -> AudioKit.Operation
}
extension ComputedParameter {
  public func reverberateWithCostello(feedback: AudioKit.OperationParameter = 0.6, cutoffFrequency: AudioKit.OperationParameter = 4_000) -> AudioKit.StereoOperation
}
extension ComputedParameter {
  public func reverberateWithFlatFrequencyResponse(reverbDuration: AudioKit.OperationParameter = 0.5, loopDuration: Swift.Double = 0.1) -> AudioKit.Operation
}
extension ComputedParameter {
  public func pitchShift(semitones: AudioKit.OperationParameter = 0) -> AudioKit.Operation
}
extension Operation {
  public static func brownianNoise(amplitude: AudioKit.OperationParameter = 1.0) -> AudioKit.Operation
}
extension Operation {
  public static func pinkNoise(amplitude: AudioKit.OperationParameter = 1.0) -> AudioKit.Operation
}
extension Operation {
  public static func whiteNoise(amplitude: AudioKit.OperationParameter = 1.0) -> AudioKit.Operation
}
extension Operation {
  public static func fmOscillator(baseFrequency: AudioKit.OperationParameter = 440, carrierMultiplier: AudioKit.OperationParameter = 1.0, modulatingMultiplier: AudioKit.OperationParameter = 1.0, modulationIndex: AudioKit.OperationParameter = 1.0, amplitude: AudioKit.OperationParameter = 0.5) -> AudioKit.Operation
}
extension Operation {
  public static func morphingOscillator(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 1, index: AudioKit.OperationParameter = 0) -> AudioKit.Operation
}
extension Operation {
  public static func phasor(frequency: AudioKit.OperationParameter = 1, phase: Swift.Double = 0) -> AudioKit.Operation
}
extension Operation {
  public static func sawtooth(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 0.5, phase: AudioKit.OperationParameter = 0) -> AudioKit.Operation
  public static func reverseSawtooth(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 0.5, phase: AudioKit.OperationParameter = 0) -> AudioKit.Operation
}
extension Operation {
  public static func sawtoothWave(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 0.5) -> AudioKit.Operation
}
extension Operation {
  public static func sineWave(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 1) -> AudioKit.Operation
}
extension Operation {
  public static func square(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 0.5, phase: AudioKit.OperationParameter = 0) -> AudioKit.Operation
}
extension Operation {
  public static func squareWave(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 1.0, pulseWidth: AudioKit.OperationParameter = 0.5) -> AudioKit.Operation
}
extension Operation {
  public static func triangle(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 0.5, phase: AudioKit.OperationParameter = 0) -> AudioKit.Operation
}
extension Operation {
  public static func triangleWave(frequency: AudioKit.OperationParameter = 440, amplitude: AudioKit.OperationParameter = 0.5) -> AudioKit.Operation
}
extension Operation {
  public static func pluckedString(trigger: AudioKit.Operation, frequency: AudioKit.OperationParameter = 110, amplitude: AudioKit.OperationParameter = 0.5, lowestFrequency: Swift.Double = 110) -> AudioKit.Operation
}
extension Operation {
  public static func vocalTract(frequency: AudioKit.OperationParameter = 160.0, tonguePosition: AudioKit.OperationParameter = 0.5, tongueDiameter: AudioKit.OperationParameter = 1.0, tenseness: AudioKit.OperationParameter = 0.6, nasality: AudioKit.OperationParameter = 0.0) -> AudioKit.Operation
}
extension Operation {
  public static func jitter(amplitude: AudioKit.OperationParameter = 0.5, minimumFrequency: AudioKit.OperationParameter = 0.5, maximumFrequency: AudioKit.OperationParameter = 4) -> AudioKit.Operation
}
extension Operation {
  public static func randomNumberPulse(minimum: AudioKit.OperationParameter = 0, maximum: AudioKit.OperationParameter = 1, updateFrequency: AudioKit.OperationParameter = 10) -> AudioKit.Operation
}
extension Operation {
  public static func randomVertexPulse(minimum: AudioKit.OperationParameter = 0, maximum: AudioKit.OperationParameter = 1, updateFrequency: AudioKit.OperationParameter = 3) -> AudioKit.Operation
}
extension Operation {
  public func plus(_ parameter: AudioKit.OperationParameter) -> AudioKit.Operation
  public func offsetBy(_ parameter: AudioKit.OperationParameter) -> AudioKit.Operation
}
public func + (left: AudioKit.OperationParameter, right: AudioKit.OperationParameter) -> AudioKit.Operation
extension StereoOperation {
  public static func + (first: AudioKit.StereoOperation, second: AudioKit.StereoOperation) -> AudioKit.StereoOperation
}
extension Operation {
  public func count(maximum: AudioKit.OperationParameter = 1_000_000, looping: Swift.Bool = true) -> AudioKit.Operation
}
extension Operation {
  public func dividedBy(_ denominator: AudioKit.OperationParameter) -> AudioKit.Operation
}
public func / (numerator: AudioKit.OperationParameter, denominator: AudioKit.OperationParameter) -> AudioKit.Operation
public func / (numerator: AudioKit.StereoOperation, denominator: AudioKit.OperationParameter) -> AudioKit.StereoOperation
extension Operation {
  public func increment(on trigger: AudioKit.OperationParameter, by step: AudioKit.OperationParameter = 1.0, minimum: AudioKit.OperationParameter = 0.0, maximum: AudioKit.OperationParameter = 1_000_000) -> AudioKit.Operation
}
public func max(_ x: AudioKit.ComputedParameter, _ y: AudioKit.ComputedParameter) -> AudioKit.Operation
public func max(_ operation: AudioKit.ComputedParameter, _ parameter: AudioKit.OperationParameter) -> AudioKit.Operation
public func max(_ parameter: AudioKit.OperationParameter, _ operation: AudioKit.ComputedParameter) -> AudioKit.Operation
public func min(_ x: AudioKit.ComputedParameter, _ y: AudioKit.ComputedParameter) -> AudioKit.Operation
public func min(_ operation: AudioKit.ComputedParameter, _ parameter: AudioKit.OperationParameter) -> AudioKit.Operation
public func min(_ parameter: AudioKit.OperationParameter, _ operation: AudioKit.ComputedParameter) -> AudioKit.Operation
extension Operation {
  public func times(_ parameter: AudioKit.OperationParameter) -> AudioKit.Operation
  public func scaledBy(_ parameter: AudioKit.OperationParameter) -> AudioKit.Operation
}
public func * (left: AudioKit.OperationParameter, right: AudioKit.OperationParameter) -> AudioKit.Operation
public func * (left: AudioKit.StereoOperation, right: AudioKit.OperationParameter) -> AudioKit.StereoOperation
public func * (left: AudioKit.OperationParameter, right: AudioKit.StereoOperation) -> AudioKit.StereoOperation
extension Operation {
  public func save(parameterIndex: Swift.Int) -> AudioKit.Operation
}
extension Operation {
  public func scale(minimum: AudioKit.OperationParameter = 0, maximum: AudioKit.OperationParameter = 1) -> AudioKit.Operation
}
extension Operation {
  public static func lineSegment(trigger: AudioKit.Operation, start: AudioKit.OperationParameter, end: AudioKit.OperationParameter, duration: AudioKit.OperationParameter) -> AudioKit.Operation
}
extension Operation {
  public static func exponentialSegment(trigger: AudioKit.Operation, start: AudioKit.OperationParameter, end: AudioKit.OperationParameter, duration: AudioKit.OperationParameter) -> AudioKit.Operation
}
extension Operation {
  public func minus(_ subtrahend: AudioKit.OperationParameter) -> AudioKit.Operation
}
public func - (left: AudioKit.OperationParameter, right: AudioKit.OperationParameter) -> AudioKit.Operation
public func - (first: AudioKit.StereoOperation, second: AudioKit.StereoOperation) -> AudioKit.StereoOperation
prefix public func - (x: AudioKit.OperationParameter) -> AudioKit.Operation
prefix public func - (x: AudioKit.StereoOperation) -> AudioKit.StereoOperation
extension ComputedParameter {
  public func trackedAmplitude(_ trackedAmplitude: AudioKit.OperationParameter = 0) -> AudioKit.Operation
}
public func mixer(_ first: AudioKit.OperationParameter, _ second: AudioKit.OperationParameter, balance: AudioKit.OperationParameter = 0.5) -> AudioKit.Operation
extension ComputedParameter {
  public func pan(_ pan: AudioKit.OperationParameter = 0) -> AudioKit.StereoOperation
  public func stereoPan(_ pan: AudioKit.OperationParameter = 0) -> AudioKit.StereoOperation
}
extension Operation {
  public func gatedADSREnvelope(gate: AudioKit.OperationParameter, attack: AudioKit.OperationParameter = 0.1, decay: AudioKit.OperationParameter = 0.0, sustain: AudioKit.OperationParameter = 1, release: AudioKit.OperationParameter = 0.2) -> AudioKit.Operation
}
extension Operation {
  public static func metronome(frequency: AudioKit.OperationParameter = 2.0) -> AudioKit.Operation
}
extension Operation {
  public static func periodicTrigger(period: AudioKit.OperationParameter = 1.0) -> AudioKit.Operation
}
extension Operation {
  public func portamento(halfDuration: AudioKit.OperationParameter = 0.02) -> AudioKit.Operation
}
extension Operation {
  public func triggeredWithEnvelope(trigger: AudioKit.OperationParameter, attack: AudioKit.OperationParameter = 0.1, hold: AudioKit.OperationParameter = 0.3, release: AudioKit.OperationParameter = 0.2) -> AudioKit.Operation
}
public protocol Numeric : AudioKit.OperationParameter {
  func value() -> Swift.Double
}
extension Double : AudioKit.Numeric {
  public func value() -> Swift.Double
}
public protocol ComputedParameter : AudioKit.OperationParameter {
}
@_hasMissingDesignatedInitializers open class Operation : AudioKit.ComputedParameter {
  open var description: Swift.String {
    get
  }
  public static var leftInput: AudioKit.Operation
  public static var rightInput: AudioKit.Operation
  public static var trigger: AudioKit.Operation
  public static var parameters: [AudioKit.Operation]
  public func toMono() -> AudioKit.Operation
  public func abs() -> AudioKit.Operation
  public func floor() -> AudioKit.Operation
  public func fract() -> AudioKit.Operation
  public func log() -> AudioKit.Operation
  public func log10() -> AudioKit.Operation
  public func round() -> AudioKit.Operation
  public func midiNoteToFrequency() -> AudioKit.Operation
  public init(_ value: Swift.Double)
  public init(_ operationString: Swift.String)
  public init(module: Swift.String, setup: Swift.String = "", inputs: AudioKit.OperationParameter...)
  @objc deinit
}
public func abs(_ parameter: AudioKit.Operation) -> AudioKit.Operation
public func floor(_ operation: AudioKit.Operation) -> AudioKit.Operation
public func fract(_ operation: AudioKit.Operation) -> AudioKit.Operation
public func log(_ operation: AudioKit.Operation) -> AudioKit.Operation
public func log10(_ operation: AudioKit.Operation) -> AudioKit.Operation
public func round(_ operation: AudioKit.Operation) -> AudioKit.Operation
public class OperationEffect : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let parameter1Def: AudioKit.NodeParameterDef
  public static let parameter2Def: AudioKit.NodeParameterDef
  public static let parameter3Def: AudioKit.NodeParameterDef
  public static let parameter4Def: AudioKit.NodeParameterDef
  public static let parameter5Def: AudioKit.NodeParameterDef
  public static let parameter6Def: AudioKit.NodeParameterDef
  public static let parameter7Def: AudioKit.NodeParameterDef
  public static let parameter8Def: AudioKit.NodeParameterDef
  public static let parameter9Def: AudioKit.NodeParameterDef
  public static let parameter10Def: AudioKit.NodeParameterDef
  public static let parameter11Def: AudioKit.NodeParameterDef
  public static let parameter12Def: AudioKit.NodeParameterDef
  public static let parameter13Def: AudioKit.NodeParameterDef
  public static let parameter14Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($parameter1) public var parameter1: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter1: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter2) public var parameter2: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter2: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter3) public var parameter3: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter3: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter4) public var parameter4: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter4: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter5) public var parameter5: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter5: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter6) public var parameter6: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter6: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter7) public var parameter7: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter7: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter8) public var parameter8: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter8: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter9) public var parameter9: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter9: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter10) public var parameter10: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter10: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter11) public var parameter11: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter11: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter12) public var parameter12: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter12: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter13) public var parameter13: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter13: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter14) public var parameter14: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter14: AudioKit.NodeParameter {
    get
    set
  }
  convenience public init(_ input: AudioKit.Node, channelCount: Swift.Int, operations: (AudioKit.StereoOperation, [AudioKit.Operation]) -> [AudioKit.Operation])
  convenience public init(_ input: AudioKit.Node, operation: (AudioKit.StereoOperation, [AudioKit.Operation]) -> AudioKit.ComputedParameter)
  convenience public init(_ input: AudioKit.Node, operation: (AudioKit.StereoOperation) -> AudioKit.ComputedParameter)
  public init(_ input: AudioKit.Node, sporth: Swift.String)
  @objc deinit
}
public class OperationGenerator : AudioKit.Node {
  public var connections: [AudioKit.Node] {
    get
  }
  public var avAudioNode: AVFoundation.AVAudioNode
  public static let parameter1Def: AudioKit.NodeParameterDef
  public static let parameter2Def: AudioKit.NodeParameterDef
  public static let parameter3Def: AudioKit.NodeParameterDef
  public static let parameter4Def: AudioKit.NodeParameterDef
  public static let parameter5Def: AudioKit.NodeParameterDef
  public static let parameter6Def: AudioKit.NodeParameterDef
  public static let parameter7Def: AudioKit.NodeParameterDef
  public static let parameter8Def: AudioKit.NodeParameterDef
  public static let parameter9Def: AudioKit.NodeParameterDef
  public static let parameter10Def: AudioKit.NodeParameterDef
  public static let parameter11Def: AudioKit.NodeParameterDef
  public static let parameter12Def: AudioKit.NodeParameterDef
  public static let parameter13Def: AudioKit.NodeParameterDef
  public static let parameter14Def: AudioKit.NodeParameterDef
  @AudioKit.Parameter @_projectedValueProperty($parameter1) public var parameter1: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter1: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter2) public var parameter2: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter2: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter3) public var parameter3: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter3: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter4) public var parameter4: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter4: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter5) public var parameter5: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter5: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter6) public var parameter6: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter6: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter7) public var parameter7: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter7: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter8) public var parameter8: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter8: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter9) public var parameter9: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter9: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter10) public var parameter10: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter10: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter11) public var parameter11: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter11: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter12) public var parameter12: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter12: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter13) public var parameter13: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter13: AudioKit.NodeParameter {
    get
    set
  }
  @AudioKit.Parameter @_projectedValueProperty($parameter14) public var parameter14: AudioKit.AUValue {
    get
    set
    _modify
  }
  public var $parameter14: AudioKit.NodeParameter {
    get
    set
  }
  convenience public init(operation: ([AudioKit.Operation]) -> AudioKit.ComputedParameter)
  convenience public init(operation: () -> AudioKit.ComputedParameter)
  convenience public init(channelCount: Swift.Int, operations: ([AudioKit.Operation]) -> [AudioKit.Operation])
  public init(sporth: Swift.String = "")
  open func trigger()
  @objc deinit
}
public protocol OperationParameter : Swift.CustomStringConvertible {
  func toMono() -> AudioKit.Operation
  func toStereo() -> AudioKit.StereoOperation
}
extension OperationParameter {
  public func toMono() -> AudioKit.Operation
  public func toStereo() -> AudioKit.StereoOperation
}
open class StereoOperation : AudioKit.ComputedParameter {
  open var description: Swift.String {
    get
  }
  public func toMono() -> AudioKit.Operation
  public func left() -> AudioKit.Operation
  public func right() -> AudioKit.Operation
  public func toStereo() -> AudioKit.StereoOperation
  public static var input: AudioKit.StereoOperation
  public init(_ operationString: Swift.String)
  public init(module: Swift.String, setup: Swift.String = "", inputs: AudioKit.OperationParameter...)
  @objc deinit
}
@objc @_inheritsConvenienceInitializers open class AppleSequencer : ObjectiveC.NSObject {
  open var sequence: AudioToolbox.MusicSequence?
  open var sequencePointer: Swift.UnsafeMutablePointer<AudioToolbox.MusicSequence>?
  open var tracks: [AudioKit.MusicTrackManager]
  open var loopEnabled: Swift.Bool {
    get
  }
  @objc override dynamic public init()
  @objc deinit
  convenience public init(filename: Swift.String)
  convenience public init(fromURL fileURL: Foundation.URL)
  convenience public init(fromData data: Foundation.Data)
  public func preroll()
  public func toggleLoop()
  public func enableLooping()
  public func enableLooping(_ loopLength: AudioKit.Duration)
  public func disableLooping()
  public func setLoopInfo(_ duration: AudioKit.Duration, numberOfLoops: Swift.Int)
  public func setLength(_ length: AudioKit.Duration)
  open var length: AudioKit.Duration {
    get
  }
  public func setRate(_ rate: Swift.Double)
  open var rate: Swift.Double {
    get
  }
  public func setTempo(_ bpm: Swift.Double)
  public func addTempoEventAt(tempo bpm: Swift.Double, position: AudioKit.Duration)
  open var tempo: Swift.Double {
    get
  }
  open var allTempoEvents: [(AudioToolbox.MusicTimeStamp, Swift.Double)] {
    get
  }
  public func getTempo(at position: AudioToolbox.MusicTimeStamp) -> Swift.Double
  open var allTimeSignatureEvents: [(AudioToolbox.MusicTimeStamp, AudioKit.TimeSignature)] {
    get
  }
  public func getTimeSignature(at position: AudioToolbox.MusicTimeStamp) -> AudioKit.TimeSignature
  public func addTimeSignatureEvent(at timeStamp: AudioToolbox.MusicTimeStamp = 0.0, timeSignature: AudioKit.TimeSignature, ticksPerMetronomeClick: AudioKit.MIDIByte = 24, thirtySecondNotesPerQuarter: AudioKit.MIDIByte = 8, clearExistingEvents: Swift.Bool = true)
  public func duration(seconds: Swift.Double) -> AudioKit.Duration
  public func seconds(duration: AudioKit.Duration) -> Swift.Double
  public func play()
  public func stop()
  public func rewind()
  open var isPlaying: Swift.Bool {
    get
  }
  open var currentPosition: AudioKit.Duration {
    get
  }
  open var currentRelativePosition: AudioKit.Duration {
    get
  }
  open var trackCount: Swift.Int {
    get
  }
  open var timeResolution: Swift.UInt32 {
    get
  }
  public func loadMIDIFile(_ filename: Swift.String)
  public func loadMIDIFile(fromURL fileURL: Foundation.URL)
  public func loadMIDIFile(fromData data: Foundation.Data)
  public func addMIDIFileTracks(_ filename: Swift.String, useExistingSequencerLength: Swift.Bool = true)
  public func addMIDIFileTracks(_ url: Foundation.URL, useExistingSequencerLength: Swift.Bool = true)
  public func newTrack(_ name: Swift.String = "Unnamed") -> AudioKit.MusicTrackManager?
  public func deleteTrack(trackIndex: Swift.Int)
  public func clearRange(start: AudioKit.Duration, duration: AudioKit.Duration)
  public func setTime(_ time: AudioToolbox.MusicTimeStamp)
  public func genData() -> Foundation.Data?
  public func debug()
  @available(tvOS 12.0, *)
  public func setGlobalMIDIOutput(_ midiEndpoint: CoreMIDI.MIDIEndpointRef)
  public func nearestQuantizedPosition(quantizationInBeats: Swift.Double) -> AudioKit.Duration
  public func previousQuantizedPosition(quantizationInBeats: Swift.Double) -> AudioKit.Duration
  public func nextQuantizedPosition(quantizationInBeats: Swift.Double) -> AudioKit.Duration
}
extension MusicTrackManager {
  open var eventData: [AudioKit.AppleMIDIEvent]? {
    get
  }
  open var noteData: [AudioKit.AppleMIDIEvent]? {
    get
  }
  open var programChangeEvents: [AudioKit.MIDIProgramChangeEvent] {
    get
  }
  public func debug()
}
public struct AppleMIDIEvent {
  public var time: AudioToolbox.MusicTimeStamp
  public var type: AudioToolbox.MusicEventType
  public var data: Swift.UnsafeRawPointer?
  public var dataSize: Swift.UInt32
}
public struct MIDIProgramChangeEvent {
  public var time: AudioToolbox.MusicTimeStamp
  public var channel: AudioKit.MIDIChannel
  public var number: AudioKit.MIDIByte
}
open class MusicTrackManager {
  open var internalMusicTrack: AudioToolbox.MusicTrack?
  open var initMusicTrack: AudioToolbox.MusicTrack?
  open var sequencer: AudioKit.AppleSequencer
  open var trackPointer: Swift.UnsafeMutablePointer<AudioToolbox.MusicTrack>?
  open var initTrackPointer: Swift.UnsafeMutablePointer<AudioToolbox.MusicTrack>?
  open var isNotEmpty: Swift.Bool {
    get
  }
  open var length: AudioToolbox.MusicTimeStamp {
    get
  }
  open var initLength: AudioToolbox.MusicTimeStamp {
    get
  }
  public init(name: Swift.String = "Unnamed")
  public init(musicTrack: AudioToolbox.MusicTrack, name: Swift.String = "Unnamed")
  public init(musicTrack: AudioToolbox.MusicTrack, sequencer: AudioKit.AppleSequencer)
  public func setNodeOutput(_ node: AudioToolbox.AUNode)
  public func setLoopInfo(_ duration: AudioKit.Duration, numberOfLoops: Swift.Int)
  public func setLength(_ duration: AudioKit.Duration)
  public func setLengthSoft(_ duration: AudioKit.Duration)
  public func clear()
  public func clearMetaEvents()
  public func clearSysExEvents()
  public func clearNote(_ note: AudioKit.MIDINoteNumber)
  open var isEmpty: Swift.Bool {
    get
  }
  public func clearRange(start: AudioKit.Duration, duration: AudioKit.Duration)
  public func add(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity, position: AudioKit.Duration, duration: AudioKit.Duration, channel: AudioKit.MIDIChannel = 0)
  public func add(midiNoteData: AudioKit.MIDINoteData)
  public func replaceMIDINoteData(with trackMIDINoteData: [AudioKit.MIDINoteData])
  public func addController(_ controller: AudioKit.MIDIByte, value: AudioKit.MIDIByte, position: AudioKit.Duration, channel: AudioKit.MIDIChannel = 0)
  public func addAftertouch(_ noteNumber: AudioKit.MIDINoteNumber, pressure: AudioKit.MIDIByte, position: AudioKit.Duration, channel: AudioKit.MIDIChannel = 0)
  public func addChannelAftertouch(pressure: AudioKit.MIDIByte, position: AudioKit.Duration, channel: AudioKit.MIDIChannel = 0)
  public func addSysEx(_ data: [AudioKit.MIDIByte], position: AudioKit.Duration)
  public func addPitchBend(_ value: Swift.Int = 8_192, position: AudioKit.Duration, channel: AudioKit.MIDIChannel = 0)
  public func resetPitchBend(position: AudioKit.Duration, channel: AudioKit.MIDIChannel = 0)
  public func getMIDINoteData() -> [AudioKit.MIDINoteData]
  public func copyAndMergeTo(musicTrack: AudioKit.MusicTrackManager)
  public func copyOf() -> AudioKit.MusicTrackManager?
  public func resetToInit()
  @available(tvOS 12.0, *)
  public func setMIDIOutput(_ endpoint: CoreMIDI.MIDIEndpointRef)
  @objc deinit
}
public struct TimeSignature : Swift.CustomStringConvertible, Swift.Equatable {
  public enum TimeSignatureBottomValue : Swift.UInt8 {
    case two
    case four
    case eight
    case sixteen
    public typealias RawValue = Swift.UInt8
    public init?(rawValue: Swift.UInt8)
    public var rawValue: Swift.UInt8 {
      get
    }
  }
  public var topValue: Swift.UInt8
  public var bottomValue: AudioKit.TimeSignature.TimeSignatureBottomValue
  public init(topValue: Swift.UInt8 = 4, bottomValue: AudioKit.TimeSignature.TimeSignatureBottomValue = .four)
  public var readableTimeSignature: (Swift.Int, Swift.Int) {
    get
  }
  public var description: Swift.String {
    get
  }
  public static func == (a: AudioKit.TimeSignature, b: AudioKit.TimeSignature) -> Swift.Bool
}
public struct AutomationCurve {
  public typealias Point = CAudioKit.ParameterAutomationPoint
  public var points: [AudioKit.AutomationCurve.Point]
  public init(points: [AudioKit.AutomationCurve.Point])
  public func evaluate(initialValue: AudioKit.AUValue, resolution: Swift.Float) -> [CAudioKit.AutomationEvent]
  public func replace(range: Swift.ClosedRange<Swift.Float>, withPoints newPoints: [(Swift.Float, AudioKit.AUValue)]) -> AudioKit.AutomationCurve
}
public typealias BPM = Swift.Double
public struct Duration : Swift.CustomStringConvertible, Swift.Comparable {
  public var beats: Swift.Double
  public var sampleRate: Swift.Double
  public var tempo: Swift.Double
  public var samples: Swift.Int {
    get
    set
  }
  public var seconds: Swift.Double {
    get
  }
  public var minutes: Swift.Double {
    get
  }
  public var musicTimeStamp: AudioToolbox.MusicTimeStamp {
    get
  }
  public var description: Swift.String {
    get
  }
  public init(samples: Swift.Int, sampleRate: Swift.Double = Settings.sampleRate, tempo: AudioKit.BPM = 60)
  public init(beats: Swift.Double, tempo: AudioKit.BPM = 60)
  public init(seconds: Swift.Double, sampleRate: Swift.Double = Settings.sampleRate, tempo: AudioKit.BPM = 60)
  public static func += (lhs: inout AudioKit.Duration, rhs: AudioKit.Duration)
  public static func -= (lhs: inout AudioKit.Duration, rhs: AudioKit.Duration)
  public static func == (lhs: AudioKit.Duration, rhs: AudioKit.Duration) -> Swift.Bool
  public static func < (lhs: AudioKit.Duration, rhs: AudioKit.Duration) -> Swift.Bool
  public static func + (lhs: AudioKit.Duration, rhs: AudioKit.Duration) -> AudioKit.Duration
  public static func - (lhs: AudioKit.Duration, rhs: AudioKit.Duration) -> AudioKit.Duration
  public static func % (lhs: AudioKit.Duration, rhs: AudioKit.Duration) -> AudioKit.Duration
}
public func ceil(_ duration: AudioKit.Duration) -> AudioKit.Duration
extension ParameterAutomationPoint {
  public init(targetValue: AudioKit.AUValue, startTime: Swift.Float, rampDuration: Swift.Float)
  public func isLinear() -> Swift.Bool
}
extension ParameterAutomationPoint : Swift.Equatable {
  public static func == (lhs: CAudioKit.ParameterAutomationPoint, rhs: CAudioKit.ParameterAutomationPoint) -> Swift.Bool
}
extension SequenceNote : Swift.Equatable {
  public static func == (lhs: CAudioKit.SequenceNote, rhs: CAudioKit.SequenceNote) -> Swift.Bool
}
extension SequenceEvent : Swift.Equatable {
  public static func == (lhs: CAudioKit.SequenceEvent, rhs: CAudioKit.SequenceEvent) -> Swift.Bool
}
extension Array where Element == CAudioKit.SequenceEvent {
  public func beatTimeOrdered() -> [CAudioKit.SequenceEvent]
}
public struct NoteEventSequence : Swift.Equatable {
  public var notes: [CAudioKit.SequenceNote]
  public var events: [CAudioKit.SequenceEvent]
  public init(notes: [CAudioKit.SequenceNote] = [], events: [CAudioKit.SequenceEvent] = [])
  public mutating func add(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity = 127, channel: AudioKit.MIDIChannel = 0, position: Swift.Double, duration: Swift.Double)
  public mutating func removeEvent(at position: Swift.Double)
  public mutating func removeNote(at position: Swift.Double)
  public mutating func removeAllInstancesOf(noteNumber: AudioKit.MIDINoteNumber)
  public mutating func add(status: AudioKit.MIDIStatus, data1: AudioKit.MIDIByte, data2: AudioKit.MIDIByte, position: Swift.Double)
  public mutating func add(event: AudioKit.MIDIEvent, position: Swift.Double)
  public func beatTimeOrderedEvents() -> [CAudioKit.SequenceEvent]
  public static func == (a: AudioKit.NoteEventSequence, b: AudioKit.NoteEventSequence) -> Swift.Bool
}
open class Sequencer {
  open var tracks: [AudioKit.SequencerTrack]
  open var tempo: AudioKit.BPM {
    get
    set
  }
  open var length: Swift.Double {
    get
    set
  }
  open var loopEnabled: Swift.Bool {
    get
    set
  }
  open var isPlaying: Swift.Bool {
    get
  }
  convenience public init(targetNode: AudioKit.Node)
  required public init(targetNodes: [AudioKit.Node]? = nil)
  convenience public init(fromURL fileURL: Foundation.URL, targetNodes: [AudioKit.Node])
  public func play()
  public func playFromStart()
  public func playAfterDelay(beats: Swift.Double)
  public func stop()
  public func rewind()
  public func load(midiFileURL: Foundation.URL)
  public func load(midiFile: AudioKit.MIDIFile)
  public func add(noteNumber: AudioKit.MIDINoteNumber, velocity: AudioKit.MIDIVelocity = 127, channel: AudioKit.MIDIChannel = 0, position: Swift.Double, duration: Swift.Double, trackIndex: Swift.Int = 0)
  public func add(event: AudioKit.MIDIEvent, position: Swift.Double, trackIndex: Swift.Int = 0)
  public func clear()
  public func seek(to position: Swift.Double)
  public func pause()
  public func getTrackFor(node: AudioKit.Node) -> AudioKit.SequencerTrack?
  public func addTrack(for node: AudioKit.Node) -> AudioKit.SequencerTrack
  @objc deinit
}
open class SequencerTrack {
  public var targetNode: AudioKit.Node?
  public var length: Swift.Double {
    get
    set
  }
  public var tempo: Swift.Double {
    get
    set
  }
  public var maximumPlayCount: Swift.Double {
    get
    set
  }
  public var loopEnabled: Swift.Bool {
    get
    set
  }
  public var isPlaying: Swift.Bool {
    get
  }
  public var currentPosition: Swift.Double {
    get
  }
  public init(targetNode: AudioKit.Node?)
  @objc deinit
  public func play()
  public func playFromStart()
  public func playAfterDelay(beats: Swift.Double)
  public func stop()
  public func rewind()
  public func seek(to position: Swift.Double)
  public var sequence: AudioKit.NoteEventSequence {
    get
    set
  }
  public func clear()
  public func stopPlayingNotes()
}
public class AmplitudeTap : AudioKit.BaseTap {
  public var amplitude: Swift.Float {
    get
  }
  public var leftAmplitude: Swift.Float {
    get
  }
  public var rightAmplitude: Swift.Float {
    get
  }
  public var stereoMode: AudioKit.StereoMode
  public var analysisMode: AudioKit.AnalysisMode
  public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32 = 1_024, stereoMode: AudioKit.StereoMode = .center, analysisMode: AudioKit.AnalysisMode = .rms, handler: @escaping (Swift.Float) -> Swift.Void = { _ in })
  override public func doHandleTapBlock(buffer: AVFoundation.AVAudioPCMBuffer, at time: AVFoundation.AVAudioTime)
  override public func stop()
  @objc deinit
  override public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32)
}
public enum AnalysisMode {
  case rms
  case peak
  public static func == (a: AudioKit.AnalysisMode, b: AudioKit.AnalysisMode) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
public enum StereoMode {
  case left
  case right
  case center
  public static func == (a: AudioKit.StereoMode, b: AudioKit.StereoMode) -> Swift.Bool
  public var hashValue: Swift.Int {
    get
  }
  public func hash(into hasher: inout Swift.Hasher)
}
open class BaseTap {
  public var bufferSize: Swift.UInt32 {
    get
  }
  public var isStarted: Swift.Bool {
    get
  }
  public var bus: Swift.Int {
    get
    set
  }
  public var input: AudioKit.Node {
    get
    set
  }
  public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32)
  public func start()
  open func doHandleTapBlock(buffer: AVFoundation.AVAudioPCMBuffer, at time: AVFoundation.AVAudioTime)
  public func stop()
  public func dispose()
  @objc deinit
}
open class FFTTap : AudioKit.BaseTap {
  open var fftData: [Swift.Float]
  public typealias Handler = ([Swift.Float]) -> Swift.Void
  public var isNormalized: Swift.Bool
  public var zeroPaddingFactor: Swift.UInt32
  public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32 = 4_096, handler: @escaping AudioKit.FFTTap.Handler)
  override open func doHandleTapBlock(buffer: AVFoundation.AVAudioPCMBuffer, at time: AVFoundation.AVAudioTime)
  override public func stop()
  @objc deinit
  override public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32)
}
extension MultiChannelInputNodeTap {
  public class WriteableFile : Swift.CustomStringConvertible {
    public var description: Swift.String {
      get
    }
    public var url: Foundation.URL {
      get
    }
    public var fileFormat: AVFoundation.AVAudioFormat {
      get
    }
    public var channel: Swift.Int32 {
      get
    }
    public var file: AVFoundation.AVAudioFile? {
      get
    }
    public var amplitude: Swift.Float {
      get
    }
    public var duration: Swift.Double {
      get
    }
    public var amplitudeArray: [Swift.Float] {
      get
    }
    public var timestamp: AVFoundation.AVAudioTime? {
      get
    }
    public init(url: Foundation.URL, fileFormat: AVFoundation.AVAudioFormat, channel: Swift.Int32, ioLatency: AVFoundation.AVAudioFrameCount = 0)
    public var ioLatency: AVFoundation.AVAudioFrameCount {
      get
    }
    public var totalFramesRead: AVFoundation.AVAudioFrameCount {
      get
    }
    public var totalFramesWritten: AVFoundation.AVAudioFramePosition {
      get
    }
    public func process(buffer: AVFoundation.AVAudioPCMBuffer, time: AVFoundation.AVAudioTime, write: Swift.Bool) throws
    public func close()
    @objc deinit
  }
}
final public class MultiChannelInputNodeTap {
  public struct FileChannel {
  }
  weak final public var delegate: AudioKit.MultiChannelInputNodeTapDelegate?
  final public var fileChannels: [AudioKit.MultiChannelInputNodeTap.FileChannel]? {
    get
  }
  @AudioKit.ThreadLockedAccessor final public var files: [AudioKit.MultiChannelInputNodeTap.WriteableFile] {
    get
    set
    _modify
  }
  final public var inputNode: AVFoundation.AVAudioInputNode? {
    get
  }
  final public var isRecording: Swift.Bool {
    get
  }
  final public var recordFileType: Swift.String {
    get
  }
  final public var recordFormat: AVFoundation.AVAudioFormat? {
    get
  }
  final public var bufferFormat: AVFoundation.AVAudioFormat? {
    get
  }
  final public var fileFormat: AVFoundation.AVAudioFormat? {
    get
  }
  final public var sampleRate: Swift.Double {
    get
  }
  final public var channels: Swift.UInt32 {
    get
  }
  final public var bitsPerChannel: Swift.UInt32 {
    get
  }
  final public var bufferSize: AVFoundation.AVAudioFrameCount {
    get
    set
  }
  final public var recordEnabled: Swift.Bool {
    get
    set
  }
  final public var directory: Foundation.URL?
  final public var recordCounter: Swift.Int {
    get
    set
  }
  final public var startedAtTime: AVFoundation.AVAudioTime? {
    get
  }
  final public var stoppedAtTime: AVFoundation.AVAudioTime? {
    get
  }
  final public var durationRecorded: Foundation.TimeInterval? {
    get
  }
  final public var ioLatency: AVFoundation.AVAudioFrameCount
  public init(inputNode: AVFoundation.AVAudioInputNode)
  @objc deinit
  final public func prepare(channelMap: [Swift.Int32])
  final public func prepare(fileChannels: [AudioKit.MultiChannelInputNodeTap.FileChannel])
  final public func record()
  final public func stop()
}
public protocol MultiChannelInputNodeTapDelegate : AnyObject {
  func tapInstalled(sender: AudioKit.MultiChannelInputNodeTap)
  func tapRemoved(sender: AudioKit.MultiChannelInputNodeTap)
  func dataProcessed(sender: AudioKit.MultiChannelInputNodeTap, frameLength: AVFoundation.AVAudioFrameCount, time: AVFoundation.AVAudioTime)
}
@objc open class NodeRecorder : ObjectiveC.NSObject {
  public var node: AudioKit.Node {
    get
  }
  public var isRecording: Swift.Bool {
    get
  }
  open var durationToRecord: Swift.Double
  open var recordedDuration: Swift.Double {
    get
  }
  open var recordFormat: AVFoundation.AVAudioFormat?
  open var audioFile: AVFoundation.AVAudioFile? {
    get
  }
  public init(node: AudioKit.Node, file: AVFoundation.AVAudioFile? = NodeRecorder.createTempFile(), bus: Swift.Int = 0) throws
  public static func createTempFile() -> AVFoundation.AVAudioFile?
  public static func removeTempFiles()
  public func record() throws
  public func stop()
  public func reset() throws
  @objc deinit
  @objc override dynamic public init()
}
public class PitchTap : AudioKit.BaseTap {
  public var amplitude: Swift.Float {
    get
  }
  public var leftPitch: Swift.Float {
    get
  }
  public var rightPitch: Swift.Float {
    get
  }
  public typealias Handler = ([Swift.Float], [Swift.Float]) -> Swift.Void
  public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32 = 4_096, handler: @escaping AudioKit.PitchTap.Handler)
  @objc deinit
  override public func stop()
  override public func doHandleTapBlock(buffer: AVFoundation.AVAudioPCMBuffer, at time: AVFoundation.AVAudioTime)
  override public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32)
}
open class RawDataTap : AudioKit.BaseTap {
  open var data: [Swift.Float]
  public typealias Handler = ([Swift.Float]) -> Swift.Void
  public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32 = 1_024, handler: @escaping AudioKit.RawDataTap.Handler = { _ in })
  override open func doHandleTapBlock(buffer: AVFoundation.AVAudioPCMBuffer, at time: AVFoundation.AVAudioTime)
  override public func stop()
  @objc deinit
  override public init(_ input: AudioKit.Node, bufferSize: Swift.UInt32)
}
extension AudioKit.FormatConverter.BitDepthRule : Swift.Equatable {}
extension AudioKit.FormatConverter.BitDepthRule : Swift.Hashable {}
extension AudioKit.Settings.SessionCategory : Swift.Equatable {}
extension AudioKit.Settings.SessionCategory : Swift.Hashable {}
extension AudioKit.Settings.SessionCategory : Swift.RawRepresentable {}
extension AudioKit.Settings.BufferLength : Swift.Equatable {}
extension AudioKit.Settings.BufferLength : Swift.Hashable {}
extension AudioKit.Settings.BufferLength : Swift.RawRepresentable {}
extension AudioKit.MIDIControl : Swift.Equatable {}
extension AudioKit.MIDIControl : Swift.Hashable {}
extension AudioKit.MIDIControl : Swift.RawRepresentable {}
extension AudioKit.MIDICustomMetaEventType : Swift.Equatable {}
extension AudioKit.MIDICustomMetaEventType : Swift.Hashable {}
extension AudioKit.MIDICustomMetaEventType : Swift.RawRepresentable {}
extension AudioKit.MIDIStatusType : Swift.Equatable {}
extension AudioKit.MIDIStatusType : Swift.Hashable {}
extension AudioKit.MIDIStatusType : Swift.RawRepresentable {}
extension AudioKit.MIDISystemCommand : Swift.Equatable {}
extension AudioKit.MIDISystemCommand : Swift.Hashable {}
extension AudioKit.MIDISystemCommand : Swift.RawRepresentable {}
extension AudioKit.MIDISystemCommandType : Swift.Equatable {}
extension AudioKit.MIDISystemCommandType : Swift.Hashable {}
extension AudioKit.MIDISystemRealTimeListener.SRTState : Swift.Equatable {}
extension AudioKit.MIDISystemRealTimeListener.SRTState : Swift.Hashable {}
extension AudioKit.MIDITimeFormat : Swift.Equatable {}
extension AudioKit.MIDITimeFormat : Swift.Hashable {}
extension AudioKit.MIDITimeFormat : Swift.RawRepresentable {}
extension AudioKit.MIDIFileChunkType : Swift.Equatable {}
extension AudioKit.MIDIFileChunkType : Swift.Hashable {}
extension AudioKit.MIDIFileChunkType : Swift.RawRepresentable {}
extension AudioKit.ShakerType : Swift.Equatable {}
extension AudioKit.ShakerType : Swift.Hashable {}
extension AudioKit.ShakerType : Swift.RawRepresentable {}
extension AudioKit.SampleTriggerMode : Swift.Equatable {}
extension AudioKit.SampleTriggerMode : Swift.Hashable {}
extension AudioKit.SampleTriggerMode : Swift.RawRepresentable {}
extension AudioKit.TimeSignature.TimeSignatureBottomValue : Swift.Equatable {}
extension AudioKit.TimeSignature.TimeSignatureBottomValue : Swift.Hashable {}
extension AudioKit.TimeSignature.TimeSignatureBottomValue : Swift.RawRepresentable {}
extension AudioKit.AnalysisMode : Swift.Equatable {}
extension AudioKit.AnalysisMode : Swift.Hashable {}
extension AudioKit.StereoMode : Swift.Equatable {}
extension AudioKit.StereoMode : Swift.Hashable {}
